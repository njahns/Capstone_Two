{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "690bc9ca-a1e2-4e0a-a9d3-9c9a65938385",
   "metadata": {
    "tags": []
   },
   "source": [
    "For my capstone, I downloaded my data from the EPA's NATIONAL WATER QUALITY MONITORING COUNCIL webpage and cleaned it here in this notebook. I also downloaded data for Cherry Creek Reservoir from another source but will not clean that until(if) I have created an accurate model with the EPA data. I cleaned the EPA data to to 'match' the Cherry Creak data in terms of features, specificlly water quality parameters. Therefore, many features and paramerters were removed from the EPA dataset. Also, as I am concerned with estimating Chlorophyll-a concentrations, I deleted all data collected at depths greater than the Cherry Creek photic zone of 3 m. In addition, the EPA data was very messy and I had to make many assumptions and heavily edit. "
   ]
  },
  {
   "cell_type": "raw",
   "id": "3157d664-ce2f-4f52-a521-8a23e7a445c1",
   "metadata": {},
   "source": [
    "The EPA raw data was too large to upload to GitHub so I have it stored it my Google drive. You can access the files at https://drive.google.com/drive/folders/1P2D8vuYOdiek7ldG3coz3FNH3w7_swKW?usp=sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1909556-bcd0-425e-a1f7-2cdf8caf2c52",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0484f933-04f5-4964-a91f-8d6b144c94dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import csv\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d65300-b871-4dc2-bbc4-c9fabeadf14e",
   "metadata": {},
   "source": [
    "I downloaded my data using the 'Advanced' tab and selected these options: https://www.waterqualitydata.us/#countrycode=US&siteType=Lake%2C%20Reservoir%2C%20Impoundment&sampleMedia=Water&sampleMedia=water&characteristicType=Inorganics%2C%20Major%2C%20Metals&characteristicType=Inorganics%2C%20Major%2C%20Non-metals&characteristicType=Inorganics%2C%20Minor%2C%20Metals&characteristicType=Inorganics%2C%20Minor%2C%20Non-metals&characteristicType=Nutrient&characteristicType=Physical&mimeType=csv&sorted=no&providers=NWIS&providers=STEWARDS&providers=STORET. Data had to be broken up into nine seperate CSV files for download to be successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf3bf54-fef0-4325-b196-76e8434ab44e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked all csv data files to make sure they have the same column names in the same order before combining.\n",
    "\n",
    "# Defined function\n",
    "def check_csv_columns_in_folder(folder_path):\n",
    "    # Got all CSV files in the specified folder and sorted them alphabetically\n",
    "    csv_files = sorted([file for file in os.listdir(folder_path) if file.endswith('.csv')])\n",
    "\n",
    "    # Dictionary to store column names for each file\n",
    "    columns_dict = {}\n",
    "\n",
    "    # Iterated through each file\n",
    "    for file_name in csv_files:\n",
    "        file_path = os.path.join(folder_path, file_name)\n",
    "        with open(file_path, 'r') as csv_file:\n",
    "            # Read the first row (header) of the CSV file\n",
    "            reader = csv.reader(csv_file)\n",
    "            columns = next(reader, None)\n",
    "\n",
    "            # Added column names to the dictionary\n",
    "            columns_dict[file_path] = columns\n",
    "\n",
    "    # Checked if all files have the same columns in the same order\n",
    "    first_file_path = os.path.join(folder_path, csv_files[0])\n",
    "    for file_path, columns in columns_dict.items():\n",
    "        if columns != columns_dict[first_file_path]:\n",
    "            print(f\"Columns in {file_path} do not match the order of columns in {first_file_path}.\")\n",
    "            return False\n",
    "\n",
    "    print(\"All CSV files in the folder have the same columns in the same order.\")\n",
    "\n",
    "    # Printed the list of files assessed in alphabetical order\n",
    "    print(\"Files assessed:\")\n",
    "    for file_name in csv_files:\n",
    "        print(file_name)\n",
    "\n",
    "    return True\n",
    "\n",
    "# Folder path\n",
    "folder_path = \"/Users/carahcampini/Desktop/Capstone/Raw_Data/\"\n",
    "check_csv_columns_in_folder(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7841ed3c-6c3c-45c0-9fbf-9d173d261492",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combined CSV files into one file.\n",
    "\n",
    "# Defined function to specify the folder path containing the EPA lake data CSV files\n",
    "def stack_csv_files(folder_path, output_folder='/Users/carahcampini/Desktop/Capstone/Edited_Data', output_filename='EPA_data_01.csv'):\n",
    "    files = [f for f in os.listdir(folder_path) if f.endswith('.csv')]\n",
    "\n",
    "    # Initialized a list to store the filenames\n",
    "    concatenated_files = []\n",
    "\n",
    "    # Read the first CSV file to get the header\n",
    "    first_file_path = os.path.join(folder_path, files[0])\n",
    "    first_df = pd.read_csv(first_file_path)\n",
    "\n",
    "    # Initialized the concatenated data frame with the first file\n",
    "    concatenated_df = first_df\n",
    "    concatenated_files.append(first_file_path)\n",
    "\n",
    "    # Concatenated the remaining CSV files\n",
    "    for file in files[1:]:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        print(f\"Processing file: {file_path}\")\n",
    "        df = pd.read_csv(file_path)\n",
    "        concatenated_df = pd.concat([concatenated_df, df], ignore_index=True)\n",
    "        concatenated_files.append(file_path)\n",
    "\n",
    "    # Wrote the concatenated data frame to a new CSV file in the specified output folder\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    concatenated_df.to_csv(output_path, index=False)\n",
    "\n",
    "    # Confirmed the file was created\n",
    "    print(f\"EPA CSV files in the EPA_data folder combined into '{output_path}'.\")\n",
    "    \n",
    "    # Printed the list of concatenated files\n",
    "    print(\"Concatenated files:\")\n",
    "    for file in concatenated_files:\n",
    "        print(file)\n",
    "\n",
    "# Called the function to stack CSV files\n",
    "stack_csv_files('/Users/carahcampini/Desktop/Capstone/Raw_Data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2684e436-dde7-4455-8ff0-82e08b1dfc53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_01 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_01.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e321e8-c8fd-4856-bb23-4f27020952e7",
   "metadata": {},
   "source": [
    "## Reduced size of EPA data by removing rows and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62140e3d-5ecb-4720-88fc-9e8e94442f7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Investigated shape of EPA_data.\n",
    "EPA_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418097b4-9893-4432-a317-f9ca14751edf",
   "metadata": {
    "tags": []
   },
   "source": [
    "That is a lot of data. My computer doesn't have enough memory to work with all of that. Therefore, this section focusses of reducing the size of the CSV file by removing features and row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828706e-09da-4a24-b6c4-fc2cd999caa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of unique values in each feature.\n",
    "for column in EPA_df.columns:\n",
    "    num_unique_values = EPA_df[column].nunique()\n",
    "    print(f\"'{column}': {num_unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2946f-ad8b-4362-b600-41697dbc063e",
   "metadata": {},
   "source": [
    "### Removed empty features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96a363b-bcb8-49dc-8489-72d9b3e3fd21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looked to see how many features contain no data.\n",
    "\n",
    "# Identified features with zero unique values\n",
    "zero_unique_features = []\n",
    "for column in EPA_df.columns:\n",
    "    unique_count = EPA_df[column].nunique()\n",
    "    if unique_count == 0:\n",
    "        zero_unique_features.append(column)\n",
    "\n",
    "# Listed features with zero unique values along with their unique values\n",
    "for feature in zero_unique_features:\n",
    "    unique_values = EPA_df[feature].unique()\n",
    "    print(f\"'{feature}': {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeec6ec-1279-450a-8212-21ec5e15a29d",
   "metadata": {
    "tags": []
   },
   "source": [
    "All the unique values are NaN and not usefull to me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2b479b8-8926-4436-a6e8-88d6e2ffea23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted features with zero unique values.\n",
    "EPA_df.drop(columns=zero_unique_features, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b05c93-9b96-421a-9a1e-9c34fc20055b",
   "metadata": {},
   "source": [
    "### Removed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3fff82-098d-4681-99a7-8b97b55fd8e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values for each feature to see what the data looks like.\n",
    "for column in EPA_df.columns:\n",
    "    unique_values = EPA_df[column].unique()\n",
    "    print(f\"{column}:\", unique_values)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386f596-2bfc-4887-8736-7296782485ee",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'ResultStatusIdentifier' is 'Rejected' becasue this data is not usable.\n",
    "EPA_df.drop(EPA_df[EPA_df['ResultStatusIdentifier'] == 'Rejected'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bf6ba8-6aa3-45f5-ac2c-16be8ab78337",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'ResultSampleFractionText' is 'Bed Sediment' becasue this data if from greater than 3m.\n",
    "EPA_df.drop(EPA_df[EPA_df['ResultSampleFractionText'] == 'Bed Sediment'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cfd4dd-8190-40fd-ae07-40c718e964d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'SubjectTaxonomicName' is anything but NaN becasue this data is not relevant. I am not concerned with taxonomic data.\n",
    "EPA_df = EPA_df[EPA_df['SubjectTaxonomicName'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe9a17c-c984-4e34-bec7-4a197ad58fda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'SampleTissueAnatomyName' is anything but NaN becasue this data is not relevant. I am not concerned with tissue data.\n",
    "EPA_df = EPA_df[EPA_df['SampleTissueAnatomyName'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd49e30-b9cb-4990-8307-d95dec5739b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'ResultAnalyticalMethod/MethodQualifierTypeName' has values 'duplicate records' or 'duplicates' becasue no duplicates should be in the data.\n",
    "values_to_remove = ['duplicate records', 'duplicates']\n",
    "EPA_df.drop(EPA_df[EPA_df['ResultAnalyticalMethod/MethodQualifierTypeName'].isin(values_to_remove)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0bf565-2604-4add-a3d5-beddfa260da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removed unneeded paremeters. These parameters are not in common with the Cherry Creek data.\n",
    "values_to_remove = ['Secchi Reading Condition (choice list)', 'Specific Conductance, Calculated/Measured Ratio', 'Temperature, sample']\n",
    "EPA_df.drop(EPA_df[EPA_df['CharacteristicName'].isin(values_to_remove)].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6565d6b6-4d0e-4b65-b07f-23dddf2a1400",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'ResultLaboratoryCommentText' indicated a failed analysis.\n",
    "values_to_remove = [\n",
    "    'Failed. Quality control criteria exceeded during analysis.',\n",
    "    'Failed. Spiked lab blank recovery not acceptable.',\n",
    "    'Equipment failed, sample not analyzed',\n",
    "    'Failed. Lab performance check not acceptable.',\n",
    "    'Failed. Matrix spike recovery not acceptable.',\n",
    "    'Lab Failed, sample not analyzed'\n",
    "]\n",
    "EPA_df = EPA_df[~EPA_df['ResultLaboratoryCommentText'].isin(values_to_remove)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b53610-a6bc-4375-9aa8-0b59aa380dc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed duplicate rows.\n",
    "EPA_df = EPA_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739d3b0e-3771-4830-aeca-2a86bb0aecf7",
   "metadata": {},
   "source": [
    "### Deleted unnecessary features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cd2714-f343-4bae-bf70-4973ba4e994f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed head of specific columns to leanr more about them and determine if they can be removed from dataframe.\n",
    "print(EPA_df['ResultAnalyticalMethod/MethodIdentifier'].head(10))\n",
    "print(EPA_df['ResultAnalyticalMethod/MethodIdentifierContext'].head(10))\n",
    "print(EPA_df['ResultAnalyticalMethod/MethodName'].head(10))\n",
    "print(EPA_df['ResultAnalyticalMethod/MethodQualifierTypeName'].head(10))\n",
    "print(EPA_df['MethodDescriptionText'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938328d4-8a71-4d8b-97f0-e579102682fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "They can be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f170522-894c-4e2d-adc2-0a5c0d3ca709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropped feature because they do not contain necessary information.\n",
    "features_to_drop = [\n",
    "    'OrganizationFormalName',\n",
    "    'DataLoggerLine',\n",
    "    'ActivityStartTime/TimeZoneCode',\n",
    "    'ResultStatusIdentifier',\n",
    "    'StatisticalBaseCode',\n",
    "    'ResultValueTypeName',\n",
    "    'ResultTimeBasisText',\n",
    "    'ResultTemperatureBasisText',\n",
    "    'ResultParticleSizeBasisText',\n",
    "    'PrecisionValue',\n",
    "    'DataQuality/BiasValue',\n",
    "    'ResultCommentText',\n",
    "    'ResultSamplingPointName',\n",
    "    'BiologicalIntentName',\n",
    "    'SubjectTaxonomicName',\n",
    "    'SampleTissueAnatomyName',\n",
    "    'ResultAnalyticalMethod/MethodQualifierTypeName',\n",
    "    'LaboratoryName',\n",
    "    'AnalysisStartDate',\n",
    "    'AnalysisStartTime/Time',\n",
    "    'AnalysisStartTime/TimeZoneCode',\n",
    "    'AnalysisEndDate',\n",
    "    'AnalysisEndTime/Time',\n",
    "    'AnalysisEndTime/TimeZoneCode',\n",
    "    'ResultLaboratoryCommentCode',\n",
    "    'ResultDetectionQuantitationLimitUrl',\n",
    "    'LaboratoryAccreditationIndicator',\n",
    "    'LaboratoryAccreditationAuthorityName',\n",
    "    'TaxonomistAccreditationIndicator']\n",
    "EPA_df.drop(columns=features_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ffebe80-f916-463f-be0f-1964c1193ae9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examined sample depth column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfc0ad7-3cd0-4c33-82cd-a17418c8ef75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if 'ResultDepthHeightMeasure/MeasureValue' contain datatypes other than float and what those values are.\n",
    "\n",
    "# Extracted unique values for each data type\n",
    "unique_values_by_dtype = {}\n",
    "\n",
    "for dtype in EPA_df['ResultDepthHeightMeasure/MeasureValue'].apply(lambda x: type(x)).unique():\n",
    "    values = EPA_df[(EPA_df['ResultDepthHeightMeasure/MeasureValue'].apply(lambda x: type(x)) == dtype)]['ResultDepthHeightMeasure/MeasureValue']\n",
    "    unique_values = values.unique()\n",
    "    unique_values.sort()\n",
    "    unique_values_by_dtype[dtype] = unique_values\n",
    "\n",
    "# Printed the count and unique values for each data type\n",
    "for dtype, unique_values in unique_values_by_dtype.items():\n",
    "    print(f\"{dtype.__name__}: {len(unique_values)}, {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c416e98-7a50-4be0-bf7e-3e2b3340962e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Lots of non-numeric depths that need to be edited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41cbaed-3b15-428f-8e63-25d9fd34f60b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values containing non-numerical values.\n",
    "values_with_letters = EPA_df[\n",
    "    EPA_df['ResultDepthHeightMeasure/MeasureValue'].apply(lambda x: any(c.isalpha() or (c in string.punctuation and c != '.') for c in str(x)))\n",
    "]['ResultDepthHeightMeasure/MeasureValue']\n",
    "\n",
    "unique_values_with_letters = values_with_letters.value_counts()\n",
    "print(unique_values_with_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e9a5f6-113e-455a-8c65-d419537a298f",
   "metadata": {},
   "source": [
    "#### Removed rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37db2b23-abec-4226-881d-1a69d84a1b35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Looked at row contianing '19:40' to try to determine what value should be.\n",
    "row_containing_1940 = EPA_df[EPA_df['ResultDepthHeightMeasure/MeasureValue'] == '19:40']\n",
    "row_containing_1940"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa84227-ce99-4f0d-889d-df337993254d",
   "metadata": {
    "tags": []
   },
   "source": [
    "Could not determine what 19:40 should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d56563c-cb9e-48b7-ba7f-e5d828de2993",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed rows where 'ResultStatusIdentifier' is a string that indicates sample was not taken in surface 3m and '19:40'.\n",
    "EPA_df.drop(EPA_df[EPA_df['ResultDepthHeightMeasure/MeasureValue'].isin(['HYPO', 'BOTTOM', 'THERMOCLINE', '19:40'])].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010ac778-9302-4d30-92b1-f9b0cf2d9c78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed the values in the 'ResultDepthHeightMeasure/MeasureUnitCode' fot the 'ResultDepthHeightMeasure/MeasureValue' of other string values to determine what they shopuld be.\n",
    "\n",
    "# Specified the values to look for\n",
    "values_to_look_for = ['3.0 M', 'EPI', 'Surface']\n",
    "\n",
    "# Filtered rows based on multiple values\n",
    "filtered_rows = EPA_df[EPA_df['ResultDepthHeightMeasure/MeasureValue'].isin(values_to_look_for)]\n",
    "\n",
    "# Printed the unique values\n",
    "for value in values_to_look_for:\n",
    "    subset = filtered_rows[filtered_rows['ResultDepthHeightMeasure/MeasureValue'] == value]\n",
    "    print(f\"Value: {value}, Corresponding MeasureUnitCode: {subset['ResultDepthHeightMeasure/MeasureUnitCode'].unique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87360357-deca-4dcd-8496-bacdc749c339",
   "metadata": {
    "tags": []
   },
   "source": [
    "I will assume that 3.0 M is in meters, not ft."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a054812f-cfff-4298-9037-c8522164a60d",
   "metadata": {},
   "source": [
    "#### Edited values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342b4573-d8cb-41c4-8071-91343559c8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced 'ResultDepthHeightMeasure/MeasureValue' taken in the surface 3m with a numberical value. Replacement values are according to 'ResultDepthHeightMeasure/MeasureUnitCode'. 3.0 M will be converted back to meters in later steps.\n",
    "EPA_df['ResultDepthHeightMeasure/MeasureValue'].replace({'EPI': 0.0, 'Surface': 0.0, '3.0 M': 9.84252}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9044e42b-3eca-4ce1-8d12-90b4205f5c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted string values of the 'ResultDepthHeightMeasure/MeasureValue' column to floats.\n",
    "EPA_df['ResultDepthHeightMeasure/MeasureValue'] = EPA_df['ResultDepthHeightMeasure/MeasureValue'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfaf79b-20b1-449a-bfce-d5d7ee4e3634",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted negative values to 0 in 'ResultDepthHeightMeasure/MeasureValue' column becasue a depth can't be negative. It's possible that some of these number represent a distance from the surface set at 0. However, if this is the case, most of the negative depths are within 3 m of the surface anyways and would be retained in the dataset.\n",
    "EPA_df['ResultDepthHeightMeasure/MeasureValue'] = EPA_df['ResultDepthHeightMeasure/MeasureValue'].apply(lambda x: max(0, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da6e3eb-0a48-4dc0-8bb9-61d079042a03",
   "metadata": {},
   "source": [
    "##### Converted units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1086d-a45d-4b60-98cf-951a46a4b61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in 'ResultDepthHeightMeasure/MeasureUnitCode' to see which depth units are present.\n",
    "print(EPA_df['ResultDepthHeightMeasure/MeasureUnitCode'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a682d6f-4e4e-48eb-9280-031db5837c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted 'ResultDepthHeightMeasure/MeasureValue' to meters and changed 'ResultDepthHeightMeasure/MeasureUnitCode' to m.\n",
    "# Conversion factors\n",
    "conversion_factors = {'ft': 0.3048, 'in': 0.0254, 'cm': 0.01}\n",
    "# Applied conversions based on 'ResultDepthHeightMeasure/MeasureUnitCode'\n",
    "for unit_code, conversion_factor in conversion_factors.items():\n",
    "    mask = EPA_df['ResultDepthHeightMeasure/MeasureUnitCode'] == unit_code\n",
    "    EPA_df.loc[mask, 'ResultDepthHeightMeasure/MeasureValue'] *= conversion_factor\n",
    "    EPA_df.loc[mask, 'ResultDepthHeightMeasure/MeasureUnitCode'] = 'm'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f5798-0c5f-4e51-b8b9-602fb6e3b333",
   "metadata": {},
   "source": [
    "##### Deleted rows with depth greater than 3 m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf0c217-9c50-4e20-9e9c-87a02fa84e25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of values in ResultDepthHeightMeasure/MeasureUnitCode' greater than 3 and less than or equal to 3 to see how many rows will be deleted.\n",
    "counts = EPA_df['ResultDepthHeightMeasure/MeasureValue'].apply(lambda x: '>3' if x > 3 else '<=3').value_counts()\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89476d0e-dd2f-4b0e-a165-a4ffee978d3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Droped all rows where 'ResultDepthHeightMeasure/MeasureValue' is greater than 3 meters depth or Nan. The model to be devoped with this dataset is only concerned with the photic zone (>3 M).\n",
    "EPA_df.drop(EPA_df[EPA_df['ResultDepthHeightMeasure/MeasureValue'] > 3].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893f27c5-ac8a-4245-9af2-b82226d9e626",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_02.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652bc5e-6caf-4497-860d-268a5acdb928",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Examined columns that will be used in model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499404d0-4443-4738-a132-82957b2c89a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_02.csv into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_02.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984d808a-3256-471f-981e-b89447ac37a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Made list of remaining columns\n",
    "column_names = EPA_df.columns.tolist()\n",
    "for name in column_names:\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219ff60d-d549-4479-9827-c25c4b8a3bb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examined date and time columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c015409-f2e2-41c1-b3b2-061ad0be7fde",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of dates and listed unique values.\n",
    "\n",
    "# Printed total 'ActivityStartDate' counts.\n",
    "data_type_counts = EPA_df['ActivityStartDate'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total Date counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ActivityStartDate'][EPA_df['ActivityStartDate'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a528f-a562-480a-ae41-aac29341550d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of start times and listed unique values.\n",
    "\n",
    "# Printed total 'activityStartTime/Time' counts.\n",
    "data_type_counts = EPA_df['ActivityStartTime/Time'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total Time counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ActivityStartTime/Time'][EPA_df['ActivityStartTime/Time'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff7be59-d586-47ec-ac06-509e571721b1",
   "metadata": {},
   "source": [
    "Date and time should be combined into one feature and correctly formatted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88e4d6b-d1d9-4288-94cc-dcfde926e695",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Created 'DateTime' by combining 'ActivityStartDate' and 'ActivityStartTime/Time'.\n",
    "EPA_df['DateTime'] = EPA_df.apply(lambda row: row['ActivityStartDate'] + \" \" + row['ActivityStartTime/Time'] if not pd.isna(row['ActivityStartTime/Time']) else row['ActivityStartDate'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49392cba-f073-4dda-8dc9-8bd01a372ec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed 'DateTime' from string to timestamp and formatted.\n",
    "EPA_df['DateTime'] = pd.to_datetime(EPA_df['DateTime'], errors='ignore', format='%Y-%m-%d %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed418fc-4f63-4da4-a605-f20730609d53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of DateTime and listed unique values.\n",
    "\n",
    "# Printed total 'DateTime' counts.\n",
    "data_type_counts = EPA_df['DateTime'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total 'DateTime' and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['DateTime'][EPA_df['DateTime'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97995f79-6974-4c3b-9500-26396e704682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dropped Date and Time columns because they are no longer needed.\n",
    "EPA_df.drop(columns=['ActivityStartDate', 'ActivityStartTime/Time'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a607f050-1044-4094-8554-519e822e2b24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_03.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877a6264-f356-46fc-b62e-1737eb9b9ac0",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examined water quality parameter columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f009f800-69e9-4d47-a901-e72b16938f08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_03.csv into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe9c42-1ec1-4163-9677-09c2d38de4ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Duplicated and combined features related to parameters so I have information in one place for future reference.\n",
    "EPA_df['ParameterOrig'] = (\n",
    "    EPA_df['CharacteristicName'].fillna('') +\n",
    "    ' ' +\n",
    "    EPA_df['ResultSampleFractionText'].fillna('') +\n",
    "    ' ' +\n",
    "    EPA_df['MethodSpecificationName'].fillna('') +\n",
    "    '' +\n",
    "    EPA_df['ResultMeasure/MeasureUnitCode'].fillna('')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f94fa7e-512a-4dd8-9775-b107377e6d95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of 'MethodSpecificationName' and listed unique values.\n",
    "\n",
    "# Printed total 'MethodSpecificationName' counts\n",
    "data_type_counts = EPA_df['MethodSpecificationName'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total 'MethodSpecificationName' counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['MethodSpecificationName'][EPA_df['MethodSpecificationName'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf0748b-87f8-451e-a02d-147fb517a599",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced 'unknown' with 'NaN' and 'as Chlorophyll' with 'as Chlorophyll a' for consistancey in naming.\n",
    "EPA_df['MethodSpecificationName'].replace({'unknown': np.nan, 'as Chlorophyll': 'as Chlorophyll a'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ebede5-f181-4ff8-99b6-7d6049e73eca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of 'CharacteristicName' and listed unique values.\n",
    "\n",
    "# Printed total 'CharacteristicName' counts\n",
    "data_type_counts = EPA_df['CharacteristicName'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total 'CharacteristicName' counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = sorted(EPA_df['CharacteristicName'][EPA_df['CharacteristicName'].apply(lambda x: type(x).__name__) == data_type].unique())\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"\\nData Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    for value in unique_values:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34524c19-5e2b-4d4c-8084-6a17c6e0ec54",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed 'CharacteristicName' values to make consistant.\n",
    "\n",
    "# Mapping for replacements\n",
    "replace_mapping = {\n",
    "    'Specific conductivity***retired***use Specific conductance': 'Specific conductance',\n",
    "    'Inorganic nitrogen (ammonia, nitrate and nitrite)***retired***use Inorganic nitrogen (NO2, NO3, & NH3)': 'Inorganic nitrogen (NO2, NO3, & NH3)',\n",
    "    'Inorganic nitrogen (nitrate and nitrite) ***retired***use Nitrate + Nitrite': 'Inorganic nitrogen (NO2 & NO3)',\n",
    "    'Inorganic nitrogen (nitrate and nitrite)': 'Inorganic nitrogen (NO2 & NO3)',\n",
    "    'Inorganic nitrogen (nitrate and nitrite) as N': 'Inorganic nitrogen (NO2 & NO3) as N',\n",
    "    'Nitrate + Nitrite': 'Inorganic nitrogen (NO2 & NO3)',\n",
    "    'Chlorophyll': 'Chlorophyll a',\n",
    "    'Chlorophyll a (probe relative fluorescence)': 'Chlorophyll a',\n",
    "    'Chlorophyll a (probe)': 'Chlorophyll a',\n",
    "    'Chlorophyll a - Phytoplankton (suspended)': 'Chlorophyll a',\n",
    "    'Chlorophyll a, uncorrected for pheophytin': 'Chlorophyll a',\n",
    "}\n",
    "\n",
    "# Replaced values in 'CharacteristicName' using the mapping for full matches\n",
    "EPA_df['CharacteristicName'] = EPA_df['CharacteristicName'].replace(replace_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2102f994-c0cf-432d-932d-e6913a78dfb4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed count of 'ResultSampleFractionText' and listed unique values.\n",
    "\n",
    "\n",
    "# Printed total 'ResultSampleFractionText' counts\n",
    "data_type_counts = EPA_df['ResultSampleFractionText'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total 'ResultSampleFractionText' counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ResultSampleFractionText'][EPA_df['ResultSampleFractionText'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_values = sorted(unique_values)  # Sort the unique values alphabetically\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values:\")\n",
    "    for value in unique_values:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cf1103-1b1f-4658-9906-1aa3e3a79fb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed some 'ResultSampleFractionText' values to make consistant.\n",
    "\n",
    "# Mapping for replacements\n",
    "replace_mapping = {\n",
    "    ' ': np.NaN,\n",
    "    'Non-filterable': 'Total',\n",
    "    'Non-Filterable (Particle)': 'Total',\n",
    "    'Unfiltered': 'Total',\n",
    "    'Unfiltered, field': 'Total',\n",
    "    'Filterable': 'Dissolved',\n",
    "    'Filtered, field': 'Dissolved',\n",
    "    'Filtered, lab': 'Dissolved',\n",
    "    'Recoverable': 'Total',\n",
    "    'Total Recoverable': 'Total',\n",
    "    'Acid Soluble': np.NaN,\n",
    "    'Field': np.NaN,\n",
    "    'Fixed': np.NaN,\n",
    "    'Free Available': 'Dissolved',\n",
    "    'Supernate': 'Dissolved',\n",
    "    'Suspended': np.NaN,\n",
    "    'Total Residual': np.NaN,\n",
    "    'Total Soluble': 'Dissolved'\n",
    "}\n",
    "\n",
    "# Replaced values in 'CharacteristicName' using the mapping for full matches\n",
    "EPA_df['ResultSampleFractionText'] = EPA_df['ResultSampleFractionText'].replace(replace_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0454dcc-9318-47b4-bcd7-0d8a0d7a6fd6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combined the parameter columns so all info was in one column for more name editing.\n",
    "EPA_df['Parameter'] = EPA_df[['CharacteristicName', 'ResultSampleFractionText', 'MethodSpecificationName']].fillna('').apply(lambda row: ', '.join(filter(None, row)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04da290e-46b6-4af6-aa30-5eae366eed6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaned up spaces in parameter values.\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].str.replace('\\s+', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e31b6a9-2424-4880-9cdb-4dad8ef0260b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in 'Parameter' to see what needs to be edited for consistancy.\n",
    "unique_values_parameter = sorted(EPA_df['Parameter'].unique())\n",
    "for value in unique_values_parameter:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d2411e-a646-4892-a8bb-725efe0ecc4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Names are inconsistant resulting in multiple versions for the same parameter, format is not consistant between perameters, and some information in a name contradictions other information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be52bc-23eb-4730-9e42-2dd38dac040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed 'MethodSpecificationName' portion of 'Parameter' values to fix data entry mistakes.\n",
    "\n",
    "# Mapping for replacements\n",
    "replace_mapping = {\n",
    "    'Alkalinity, total, Total, as N': 'Alkalinity, Total',\n",
    "    'Alkalinity, total, Total, as NO3': 'Alkalinity, Total',\n",
    "    'Ammonia-nitrogen, Total, as CaCO3': 'Ammonia-nitrogen, Total',\n",
    "    'Calcium hydroxide, as CaCO3': 'Calcium hydroxide',\n",
    "    'Calcium hydroxide, Total, as CaCO3': 'Calcium hydroxide, Total',\n",
    "    'Chloride, Dissolved, as P': 'Chloride, Dissolved',\n",
    "    'Chloride, Total, as N': 'Chloride, Total',\n",
    "    'Chlorophyll a, Total, as N': 'Chlorophyll a',\n",
    "    'Chlorophyll a, Total, as S': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as CaCO3': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as Cl': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as Cl': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as N': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as P': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as PO4': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as SO4': 'Chlorophyll a',\n",
    "    'Chlorophyll a, as SiO2': 'Chlorophyll a',\n",
    "    'Conductivity, as N': 'Conductivity',\n",
    "    'Conductivity, as PO4': 'Conductivity',\n",
    "    'Dissolved oxygen (DO), as N': 'Dissolved oxygen (DO)',\n",
    "    'Dissolved oxygen (DO), as O2': 'Dissolved oxygen (DO)',\n",
    "    'Dissolved oxygen (DO), as PO4': 'Dissolved oxygen (DO)',\n",
    "    'Hardness, carbonate, Total, as P': 'Hardness, carbonate, Total',\n",
    "    'Hardness, non-carbonate, Dissolved, as CaCO3': 'Hardness, non-carbonate, Dissolved',\n",
    "    'Hardness, non-carbonate, Total, as CaCO3': 'Hardness, non-carbonate, Total',\n",
    "    'Hydroxide, Total, as CaCO3': 'Hydroxide, Total',\n",
    "    'Kjeldahl nitrogen, Total, as CaCO3': 'Kjeldahl nitrogen, Total',\n",
    "    'Kjeldahl nitrogen, Total, as NH4': 'Kjeldahl nitrogen, Total',\n",
    "    'Kjeldahl nitrogen, Total, as NO3': 'Kjeldahl nitrogen, Total',\n",
    "    'Nitrate, Dissolved, as NO2': 'Nitrate, Dissolved',\n",
    "    'Nitrate, Total, as NO2': 'Nitrate, Total',\n",
    "    'Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3), Total, as NO3': 'Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3), Total',\n",
    "    'Nitrogen, Dissolved, as NO2': 'Nitrogen, Dissolved',\n",
    "    'Nitrogen, Dissolved, as NO3': 'Nitrogen, Dissolved',\n",
    "    'Phosphorus, Dissolved, as N': 'Phosphorus, Dissolved',\n",
    "    'Phosphorus, Total, as N': 'Phosphorus, Total',\n",
    "    'Sulfate, Total, as CaCO3': 'Sulfate, Total',\n",
    "    'Sulfate, Total, as Cl': 'Sulfate, Total',\n",
    "    'Sulfate, Total, as N': 'Sulfate, Total',\n",
    "    'Sulfate, Total, as P': 'Sulfate, Total',\n",
    "    'Sulfate, Total, as S': 'Sulfate, Total',\n",
    "    'Temperature, water, as N': 'Temperature, water',\n",
    "    'Temperature, water, as PO4': 'Temperature, water',\n",
    "    'pH, Dissolved, as pH': 'pH, Dissolved',\n",
    "    'pH, as N': 'pH',\n",
    "    'pH, as PO4': 'pH',\n",
    "    'pH, as pH': 'pH'\n",
    "}\n",
    "\n",
    "# Replaced values in 'CharacteristicName' using the mapping for full matches\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].replace(replace_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c3a32-ea8f-42fe-bd59-351f1e8fba90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of unique 'ResultMeasure/MeasureUnitCode' to see what could be helpful for naming parameters.\n",
    "\n",
    "# Printed total 'ResultMeasure/MeasureUnitCode' counts\n",
    "data_type_counts = EPA_df['ResultMeasure/MeasureUnitCode'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the total 'ResultMeasure/MeasureUnitCode' counts and unique values\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ResultMeasure/MeasureUnitCode'][EPA_df['ResultMeasure/MeasureUnitCode'].apply(lambda x: type(x).__name__) == data_type].unique()\n",
    "    unique_values = sorted(unique_values)  # Sort the unique values alphabetically\n",
    "    unique_count = len(unique_values)\n",
    "    \n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_count}\")\n",
    "    print(f\"Unique Values:\")\n",
    "    for value in unique_values:\n",
    "        print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426e57aa-c0b9-4f66-af72-194e0318889b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selected 'ResultMeasure/MeasureUnitCode' values that provide more information for 'Paramters'.\n",
    "\n",
    "# Filtered for 'ResultMeasure/MeasureUnitCode'\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasure/MeasureUnitCode'].isin(['mg/l CaCO3**', 'mg/l CaCO3', 'mg/l asNO3', 'mg/l as N', 'mg/l asPO4', 'mg/l as P', 'mg/l NH4', 'mg/l NO3', 'mg/l asNO2', 'mg/l PO4', 'mg/kg as N', 'mg/kg as P', 'ug/L as P', 'ug/l as P'])]\n",
    "\n",
    "# Displayed filtered 'ResultMeasure/MeasureUnitCode' and 'Paramter' values\n",
    "unique_pairs = filtered_df[['Parameter', 'ResultMeasure/MeasureUnitCode']].drop_duplicates().sort_values(by='Parameter')\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "unique_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75678e0c-2863-4a51-8c9d-310aeee483ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed full name so I could see full length.\n",
    "value_at_index = EPA_df.at[23521161, 'Parameter']\n",
    "print(value_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178d0c2b-f783-4a6a-bbee-9f97b1c18e67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed full name so I could see full length.\n",
    "value_at_index = EPA_df.at[14721778, 'Parameter']\n",
    "print(value_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62b6859-8ff7-4f3d-ac8a-3f2a034ae7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed full name so I could see full length.\n",
    "value_at_index = EPA_df.at[3771489, 'Parameter']\n",
    "print(value_at_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7032442d-8776-4071-88b3-d0e1e74b30af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Added info from 'ResultMeasure/MeasureUnitCode' to 'Parameter' where above table could not distinguish.\n",
    "\n",
    "# Defined the conditions for updating the 'Parameter' column\n",
    "conditions = [\n",
    "    (EPA_df['Parameter'] == \"Nitrate, Dissolved\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrate, Total\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrite, Dissolved\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrite, Total\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrogen, mixed forms (NH3), (NH4), organic\") | \n",
    "    (EPA_df['Parameter'] == \"Orthophosphate, Dissolved\") | \n",
    "    (EPA_df['Parameter'] == \"Phosphorus, Dissolved\") | \n",
    "    (EPA_df['Parameter'] == \"Phosphorus, Total\") | \n",
    "    (EPA_df['Parameter'] == \"Alkalinity, Phenolphthalein (total hydroxide+1/2 carbonate), Total\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3), Dissolved\") | \n",
    "    (EPA_df['Parameter'] == \"Nitrogen, mixed forms (NH3), (NH4), organic, (NO2) and (NO3), Total\"),\n",
    "    EPA_df['ResultMeasure/MeasureUnitCode'].notna()\n",
    "]\n",
    "\n",
    "# Defined the values to be added from 'ResultMeasure/MeasureUnitCode' column\n",
    "values_to_add = EPA_df['ResultMeasure/MeasureUnitCode']\n",
    "\n",
    "# Updated the 'Parameter' column based on the conditions\n",
    "EPA_df['Parameter'] = np.where(conditions[0] & conditions[1], EPA_df['Parameter'] + ', ' + values_to_add, EPA_df['Parameter'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e576b0bf-6e8d-4681-86d9-d5c32add4326",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in 'Parameter' to see what needs to be edited to make consistant.\n",
    "unique_values_parameter = sorted(EPA_df['Parameter'].unique())\n",
    "for value in unique_values_parameter:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dec7a5b-72fd-4479-9d94-80ae137fd889",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Edited 'Parameters' to fix entry errors and remove unnecessary information.\n",
    "\n",
    "# Defined a mapping for replacements\n",
    "replacement_mapping = {\n",
    "    'total': 'Total',\n",
    "    'bicarbonate': 'Bicarbonate',\n",
    "    'ammonium': 'Ammonium',\n",
    "    r'\\bcarbonate\\b': 'Carbonate',\n",
    "    'nitrogen': 'Nitrogen',\n",
    "    'oxygen': 'Oxygen',\n",
    "    'saturation': 'Saturation',\n",
    "    'non-': 'Non-',\n",
    "    'phosphorus': 'Phosphorus',\n",
    "    'transmissivity': 'Transmissivity',\n",
    "    'attenuation': 'Attenuation',\n",
    "    'depth': 'Depth',\n",
    "    'asNO3': 'as NO3',\n",
    "    'asNO2': 'as NO2',\n",
    "    'asPO4': 'as PO4',\n",
    "    'mixed forms': 'Mixed Forms',\n",
    "    'organic': 'Organic',\n",
    "    'transparency': 'Transparency',\n",
    "    r'\\bion\\b': 'Ion',\n",
    "    'carbon': 'Carbon',\n",
    "    'solids': 'Solids',\n",
    "    'suspended': 'Suspended',\n",
    "    'volatile': 'Volatile',\n",
    "    'hydroxide': 'Hydroxide',\n",
    "    ' mg/l': '',\n",
    "    ' mg/L': '',\n",
    "    ' ug/L': '',\n",
    "    '\\*\\*': '',\n",
    "    ' ug/l': '',\n",
    "    ' %': '',\n",
    "    ' mg/kg': '',\n",
    "    'ppb': '',\n",
    "    'ppm': '',\n",
    "    ', sample': '',\n",
    "    ', water': '',\n",
    "    ' disc': ''\n",
    "}\n",
    "\n",
    "# Applied replacements to the 'Parameter' column for partial matches\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].replace(replacement_mapping, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db74038a-0d39-4d49-9077-5b153ea6c64c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed commas and spaces at the end of values in the 'Parameter' column.\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].str.rstrip(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2767da31-c4ef-4e5e-b586-1eeafcd86169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in 'Parameter' to see what needs to be edited to make consistant.\n",
    "unique_values_parameter = sorted(EPA_df['Parameter'].unique())\n",
    "for value in unique_values_parameter:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b8efa8b-023b-4803-80d7-da4f5a1fd9b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV\n",
    "EPA_df.to_csv('EPA_data_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd188a1a-5052-47d7-8f29-d5dcaac6a75f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_04 file into pandas DataFrame\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_04.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f52ab-5623-4da9-a46a-90c05c124bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changed 'Parameter' values to make consistant.\n",
    "\n",
    "# Mapping for replacements\n",
    "replace_mapping = {\n",
    "    'Alkalinity': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Total': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Total, Total': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Total, Total, as CaCO3': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Total, as CaCO3': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Total, InOrganic': 'Alkalinity, Total, as CaCO3',\n",
    "    'Alkalinity, Dissolved': 'Alkalinity, Dissolved, as CaCO3',\n",
    "    'Alkalinity, Total, Dissolved': 'Alkalinity, Dissolved, as CaCO3',\n",
    "    'Alkalinity, Total, Dissolved, as CaCO3': 'Alkalinity, Dissolved, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'BiCarbonate': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate as CaCO3': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate, as CaCO3': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'BiCarbonate, as CaCO3': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate, Total': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate, Total, as CaCO3': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate as CaCO3, Total': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'BiCarbonate, Total': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'BiCarbonate, Total, as CaCO3': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'BiCarbonate, InOrganic': 'Alkalinity, Bicarbonate, Total, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate, Dissolved': 'Alkalinity, Bicarbonate, Dissolved, as CaCO3',\n",
    "    'Alkalinity, BiCarbonate, Dissolved, as CaCO3': 'Alkalinity, Bicarbonate, Dissolved, as CaCO3',\n",
    "    'BiCarbonate, Dissolved': 'Alkalinity, Bicarbonate, Dissolved, as CaCO3',\n",
    "    'BiCarbonate, Dissolved, as CaCO3': 'Alkalinity, Bicarbonate, Dissolved, as CaCO3',\n",
    "    'BiCarbonate, as HCO3': 'Alkalinity, Bicarbonate, Total, as HCO3',\n",
    "    'BiCarbonate, Dissolved, as HCO3': 'Alkalinity, Bicarbonate, Dissolved, as HCO3',\n",
    "    'BiCarbonate, Total, as HCO3': 'Alkalinity, Bicarbonate, Total, as HCO3',\n",
    "    'Alkalinity, Carbonate': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Carbonate': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Alkalinity, Carbonate, Total': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Carbonate, Total': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Alkalinity, Carbonate as CaCO3, Total': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Carbonate, Total, as CaCO3': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Carbonate, as CaCO3': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Alkalinity, Carbonate as CaCO3': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Alkalinity, Carbonate, as CaCO3': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Carbonate, InOrganic': 'Alkalinity, Carbonate, Total, as CaCO3',\n",
    "    'Alkalinity, Carbonate, Dissolved': 'Alkalinity, Carbonate, Dissolved, as CaCO3',\n",
    "    'Carbonate, Dissolved': 'Alkalinity, Carbonate, Dissolved, as CaCO3',\n",
    "    'Carbonate, Dissolved, as CaCO3': 'Alkalinity, Carbonate, Dissolved, as CaCO3',\n",
    "    'Carbonate, Total, as CO3': 'Alkalinity, Carbonate, Total, as CO3',\n",
    "    'Carbonate, Dissolved, as CO3': 'Alkalinity, Carbonate, Dissolved, as CO3',\n",
    "    'Alkalinity, Hydroxide': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Alkalinity, Hydroxide as CaCO3': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Alkalinity, Hydroxide, as CaCO3': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Hydroxide, Total': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Alkalinity, Hydroxide, Total': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Alkalinity, Hydroxide as CaCO3, Total': 'Alkalinity, Hydroxide, Total, as CaCO3',\n",
    "    'Alkalinity, Hydroxide, Dissolved': 'Alkalinity, Hydroxide, Dissolved, as CaCO3',\n",
    "    'Hydroxide, Dissolved': 'Alkalinity, Hydroxide, Dissolved, as CaCO3',\n",
    "    'Hydroxide, Total, as OH': 'Alkalinity, Hydroxide, Total, as OH',\n",
    "    'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate)': 'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total, as CaCO3',\n",
    "    'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total': 'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total, as CaCO3',\n",
    "    'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total, CaCO3': 'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total, as CaCO3',\n",
    "    'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), as CaCO3': 'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Total, as CaCO3',\n",
    "    'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Dissolved': 'Alkalinity, Phenolphthalein (Total Hydroxide+1/2 Carbonate), Dissolved, as CaCO3',\n",
    "    'Bromide': 'Bromide, Total',\n",
    "    'Calcium Carbonate': 'Calcium Carbonate, Total, as CaCO3',\n",
    "    'Calcium Carbonate, Total': 'Calcium Carbonate, Total, as CaCO3',\n",
    "    'Calcium Carbonate, as CaCO3': 'Calcium Carbonate, Total, as CaCO3',\n",
    "    'Calcium Hydroxide': 'Calcium Hydroxide, Total, as CaCO3',\n",
    "    'Carbon': 'Carbon, Total',\n",
    "    'Total Carbon': 'Carbon, Total',\n",
    "    'Total Carbon, Total': 'Carbon, Total',\n",
    "    'Total Carbon, Total, as C': 'Carbon, Total',\n",
    "    'Chloride': 'Chloride, Total',\n",
    "    'Chloride, Total, as Cl': 'Chloride, Total',\n",
    "    'Chloride, as Cl': 'Chloride, Total',\n",
    "    'Chloride, InOrganic': 'Chloride, Total',\n",
    "    'Chloride, Dissolved': 'Chloride, Dissolved',\n",
    "    'Chloride, Dissolved, as Cl': 'Chloride, Dissolved',\n",
    "    'Chloride, Total, as CaCO3': 'Chloride, Total',\n",
    "    'Chlorophyll a': 'Chlorophyll a, Total',\n",
    "    'Chlorophyll a, Total, as Chlorophyll a': 'Chlorophyll a, Total',\n",
    "    'Chlorophyll a, as Chlorophyll a': 'Chlorophyll a, Total',\n",
    "    'Conductivity': 'Conductivity, Total',\n",
    "    'Specific conductance, Dissolved': 'Conductivity, Total',\n",
    "    'Specific conductance, Total': 'Conductivity, Total',\n",
    "    'Specific conductance': 'Conductivity, Total',\n",
    "    'Dissolved Oxygen (DO), Dissolved': 'Dissolved Oxygen',\n",
    "    'Dissolved Oxygen (DO), Total': 'Dissolved Oxygen',\n",
    "    'Dissolved Oxygen (DO)': 'Dissolved Oxygen',\n",
    "    'Dissolved Oxygen Saturation, Total': 'Dissolved Oxygen, Saturation',\n",
    "    'Dissolved Oxygen Saturation, Dissolved': 'Dissolved Oxygen, Saturation',\n",
    "    'Hardness, Carbonate': 'Hardness, Carbonate, Total, as CaCO3',\n",
    "    'Hardness, Carbonate, Total': 'Hardness, Carbonate, Total, as CaCO3',\n",
    "    'Hardness, Carbonate, as CaCO3': 'Hardness, Carbonate, Total, as CaCO3',\n",
    "    'Hardness, Carbonate, Dissolved': 'Hardness, Carbonate, Dissolved, as CaCO3',\n",
    "    'Hardness, Non-Carbonate': 'Hardness, Non-Carbonate, Total',\n",
    "    'Light Attenuation, Depth at 99%, Total': 'Light Attenuation, Depth at 99%',\n",
    "    'Nitrogen': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen Ion': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen Ion, Total': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Total': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, as N': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3)': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Total': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Total, as N': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), as N': 'Nitrogen, Total, as N',\n",
    "    'Total Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Total, as N': 'Nitrogen, Total, as N',\n",
    "    'Total Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), as N': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Total, NO3': 'Nitrogen, Total, as N',\n",
    "    'Nitrogen, Dissolved': 'Nitrogen, Dissolved, as N',\n",
    "    'Nitrogen Ion, Dissolved': 'Nitrogen, Dissolved, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Dissolved': 'Nitrogen, Dissolved, as N',\n",
    "    'Nitrogen, Mixed Forms (NH3), (NH4), Organic, (NO2) and (NO3), Dissolved, as N': 'Nitrogen, Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3)': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3)': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3) as N': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Total, as N': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), as N': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Total': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3) as N, Total': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Total, as NO3': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), as NO3': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3) as N, Dissolved': 'Nitrogen (NO2 & NO3), Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Dissolved': 'Nitrogen (NO2 & NO3), Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Dissolved, as N': 'Nitrogen (NO2 & NO3), Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Dissolved, as NO3': 'Nitrogen (NO2 & NO3), Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2, NO3, & NH3)': 'Nitrogen (NO2, NO3, & NH3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2, NO3, & NH3), Total, as N': 'Nitrogen (NO2, NO3, & NH3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2, NO3, & NH3), Total': 'Nitrogen (NO2, NO3, & NH3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2, NO3, & NH3), Dissolved, as N': 'Nitrogen (NO2, NO3, & NH3), Dissolved, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), InOrganic, as N': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), InOrganic, as NO3': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'InOrganic Nitrogen (NO2 & NO3), Volatile, as N': 'Nitrogen (NO2 & NO3), Volatile, as N',\n",
    "    'Nutrient-Nitrogen, Total': 'Nitrogen (NO3 & NH4), Total, as N',\n",
    "    'Nutrient-Nitrogen, Dissolved': 'Nitrogen (NO3 & NH4), Dissolved, as N',\n",
    "    'Nitrogen, InOrganic, as N': 'Nitrogen (NO2 & NO3), Total, as N',\n",
    "    'Organic Nitrogen': 'Nitrogen, Total Organic, as N',\n",
    "    'Organic Nitrogen, Total': 'Nitrogen, Total Organic, as N',\n",
    "    'Organic Nitrogen, Total, as N': 'Nitrogen, Total Organic, as N',\n",
    "    'Organic Nitrogen, Dissolved, as N': 'Nitrogen, Dissolved Organic, as N',\n",
    "    'Organic Nitrogen, Dissolved': 'Nitrogen, Dissolved Organic, as N',\n",
    "    'Kjeldahl Nitrogen': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, Total': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, Total, as N': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, as N': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Total Kjeldahl Nitrogen, Total': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Total Kjeldahl Nitrogen, Total, as N': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Total Kjeldahl Nitrogen, as N': 'Nitrogen (NH4, org), Total Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, Volatile, as N': 'Nitrogen (NH4, org), Total Volatile Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, Dissolved': 'Nitrogen (NH4, org), Dissolved Kjeldahl, as N',\n",
    "    'Kjeldahl Nitrogen, Dissolved, as N': 'Nitrogen (NH4, org), Dissolved Kjeldahl, as N',\n",
    "    'Total Kjeldahl Nitrogen, Dissolved, as N': 'Nitrogen (NH4, org), Dissolved Kjeldahl, as N',\n",
    "    'Ammonia': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia, Total, as N': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia, Total': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia and Ammonium, Total': 'Ammonia (NH3) and Ammonium (NH4), Total, as N',\n",
    "    'Ammonia, as N': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-Nitrogen as N': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-Nitrogen, Total, as N': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-Nitrogen as N, Total': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-Nitrogen': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-Nitrogen, Total': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia-nitrogen, Dissolved, as NH3': 'Ammonia, Dissolved, as NH3',\n",
    "    'Ammonia-nitrogen, as NH3': 'Ammonia, Total, as NH3',\n",
    "    'Ammonia-nitrogen, Total, as NH3': 'Ammonia, Total, as NH3',\n",
    "    'Ammonia as NH3': 'Ammonia (NH3), Total, as NH3',\n",
    "    'Ammonia, as NH3': 'Ammonia (NH3), Total, as NH3',\n",
    "    'Ammonia as NH3, Total': 'Ammonia (NH3), Total, as NH3',\n",
    "    'Ammonia, Total, as NH3': 'Ammonia (NH3), Total, as NH3',\n",
    "    'Ammonia, Volatile, as N': 'Ammonia (NH3), Volatile, as N',\n",
    "    'Ammonia, Dissolved': 'Ammonia (NH3), Dissolved, as N',\n",
    "    'Ammonia, InOrganic': 'Ammonia (NH3), Total, as N',\n",
    "    'Ammonia and Ammonium, Dissolved': 'Ammonia (NH3) and Ammonium (NH4), Dissolved, as N',\n",
    "    'Ammonia-Nitrogen as N, Dissolved': 'Ammonia (NH3), Dissolved, as N',\n",
    "    'Ammonia-Nitrogen, Dissolved': 'Ammonia (NH3), Dissolved, as N',\n",
    "    'Ammonia-Nitrogen, Dissolved, as N': 'Ammonia (NH3), Dissolved, as N',\n",
    "    'Ammonium, as N': 'Ammonium (NH4), Total, as N',\n",
    "    'Ammonium as N, Total': 'Ammonium (NH4), Total, as N',\n",
    "    'Ammonium, Total': 'Ammonium (NH4), Total, as N',\n",
    "    'Ammonium as NH4, Total': 'Ammonium (NH4), Total, as NH4',\n",
    "    'Ammonium, Dissolved': 'Ammonium (NH4), Dissolved, as N',\n",
    "    'Ammonia, Dissolved, as N': 'Ammonia (NH3), Dissolved, as N',\n",
    "    'Ammonia, Dissolved, as NH3': 'Ammonia (NH3), Dissolved, as NH3',\n",
    "    'Ammonia, Dissolved, as NH4': 'Ammonia (NH3), Dissolved, as NH3',\n",
    "    'Ammonium, Dissolved, as N': 'Ammonium (NH4), Dissolved, as N',\n",
    "    'Ammonium, Dissolved, as NH4': 'Ammonium (NH4), Dissolved, as NH4',\n",
    "    'Ammonium, Total, as N': 'Ammonium (NH4), Total, as N',\n",
    "    'Ammonium, Total, as NH4': 'Ammonium (NH4), Total, as NH4',\n",
    "    'Nitrate': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate as N': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate as N, Total': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate, Total': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate, Total, as N': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate, as N': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate, InOrganic, as N': 'Nitrate (NO3), Total, as N',\n",
    "    'Nitrate, Total, as NO3': 'Nitrate (NO3), Total, as NO3',\n",
    "    'Nitrate, as NO3': 'Nitrate (NO3), Total, as NO3',\n",
    "    'Nitrate as N, Dissolved': 'Nitrate (NO3), Dissolved, as N',\n",
    "    'Nitrate, Dissolved': 'Nitrate (NO3), Dissolved, as N',\n",
    "    'Nitrate, Dissolved, as N': 'Nitrate (NO3), Dissolved, as N',\n",
    "    'Nitrate, Dissolved, as NO3': 'Nitrate (NO3), Dissolved, as NO3',\n",
    "    'Nitrite': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite as N': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite as N, Total': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite, Total': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite, Total, as N': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite, as N': 'Nitrite (NO2), Total, as N',\n",
    "    'Nitrite, Total, as NO2': 'Nitrite (NO2), Total, as NO2',\n",
    "    'Nitrite, as NO2': 'Nitrite (NO2), Total, as NO2',\n",
    "    'Nitrite, Volatile, as N': 'Nitrite (NO2), Volatile, as N',\n",
    "    'Nitrite as N, Dissolved': 'Nitrite (NO2), Dissolved, as N',\n",
    "    'Nitrite, Dissolved': 'Nitrite (NO2), Dissolved, as N',\n",
    "    'Nitrite, Dissolved, as N': 'Nitrite (NO2), Dissolved, as N',\n",
    "    'Nitrite, Dissolved, as NO2': 'Nitrite (NO2), Dissolved, as NO2',\n",
    "    'Oxidation reduction potential (ORP)': 'Oxidation Reduction Potential (ORP), Total',\n",
    "    'Oxidation reduction potential (ORP), Dissolved': 'Oxidation Reduction Potential (ORP), Dissolved',\n",
    "    'Oxidation reduction potential (ORP), Total': 'Oxidation Reduction Potential (ORP), Total',\n",
    "    'Phosphorus': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, Total': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, Total, ': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, as P': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus as P, Total': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, Total, as P': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, Total, PO4': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus, Total, as PO4': 'Phosphorus, Total, as P',\n",
    "    'Phosphorus as P, Dissolved': 'Phosphorus, Dissolved, as P',\n",
    "    'Phosphorus, Dissolved': 'Phosphorus, Dissolved, as P',\n",
    "    'Phosphorus, Dissolved, as P': 'Phosphorus, Dissolved, as P',\n",
    "    'Phosphorus, Dissolved, PO4': 'Phosphorus, Dissolved, as P',\n",
    "    'Phosphorus, Dissolved, as PO4': 'Phosphorus, Dissolved, as P',\n",
    "    'InOrganic Phosphorus': 'Phosphorus, Total Inorganic, as P',\n",
    "    'InOrganic Phosphorus, Total': 'Phosphorus, Total Inorganic, as P',\n",
    "    'Phosphorus, InOrganic, as P': 'Phosphorus, Total Inorganic, as P',\n",
    "    'Phosphorus, Total': 'Phosphorus, Total, as P',\n",
    "    'Organic Phosphorus': 'Phosphorus, Total Organic, as P',\n",
    "    'Organic Phosphorus, Total': 'Phosphorus, Total Organic, as P',\n",
    "    'Organic Phosphorus, Total, as P': 'Phosphorus, Total Organic, as P',\n",
    "    'Phosphorus, Particulate Organic, as P': 'Phosphorus, Total Particulate Organic, as P',\n",
    "    'Organic Phosphorus, as P': 'Phosphorus, Total Organic, as P',\n",
    "    'Organic Phosphorus, Dissolved': 'Phosphorus, Dissolved Organic, as P',\n",
    "    'Organic Phosphorus, Dissolved, as P': 'Phosphorus, Dissolved Organic, as P',\n",
    "    'Orthophosphate': 'Orthophosphate, Total, as P',\n",
    "    'Orthophosphate as P': 'Orthophosphate, Total, as P',\n",
    "    'Orthophosphate, as P': 'Orthophosphate, Total, as P',\n",
    "    'Orthophosphate as P, Total': 'Orthophosphate, Total, as P',\n",
    "    'Orthophosphate, Total': 'Orthophosphate, Total, as P',\n",
    "    'Soluble Reactive Phosphorus (SRP)': 'Orthophosphate, Total, as P',\n",
    "    'Soluble Reactive Phosphorus (SRP), Total': 'Orthophosphate, Total, as P',\n",
    "    'Soluble Reactive Phosphorus (SRP), Total, as P': 'Orthophosphate, Total, as P',\n",
    "    'Orthophosphate as PO4, Total': 'Orthophosphate, Total, as PO4',\n",
    "    'Orthophosphate, Total, as PO4': 'Orthophosphate, Total, as PO4',\n",
    "    'Orthophosphate, as PO4': 'Orthophosphate, Total, as PO4',\n",
    "    'Orthophosphate as PO4': 'Orthophosphate, Total, as PO4',\n",
    "    'Orthophosphate as P, Dissolved': 'Orthophosphate, Dissolved, as P',\n",
    "    'Orthophosphate, Dissolved, as P': 'Orthophosphate, Dissolved, as P',\n",
    "    'Orthophosphate, Dissolved': 'Orthophosphate, Dissolved, as P',\n",
    "    'Orthophosphate as PO4, Dissolved': 'Orthophosphate, Dissolved, as PO4',\n",
    "    'Soluble Reactive Phosphorus (SRP), Dissolved': 'Orthophosphate, Dissolved, as P',\n",
    "    'Soluble Reactive Phosphorus (SRP), Dissolved, as P': 'Orthophosphate, Dissolved, as P',\n",
    "    'Orthophosphate, Organic': 'Orthophosphate, Total, as P',\n",
    "    'Sulfate': 'Sulfate, Total, as S',\n",
    "    'Sulfate as S': 'Sulfate, Total, as S',\n",
    "    'Sulfate, Total': 'Sulfate, Total, as S',\n",
    "    'Sulfate as S, Total': 'Sulfate, Total, as S',\n",
    "    'Sulfate, as SO4': 'Sulfate, Total, as SO4',\n",
    "    'Sulfate as SO4': 'Sulfate, Total, as SO4',\n",
    "    'Sulfate as SO4, Total': 'Sulfate, Total, as SO4',\n",
    "    'Sulfate, Dissolved': 'Sulfate, Dissolved, as S',\n",
    "    'Sulfate, Dissolved, as S': 'Sulfate, Dissolved, as S',\n",
    "    'Sulfate as SO4, Dissolved': 'Sulfate, Dissolved, as SO4',\n",
    "    'Sulfate, Dissolved, as SO4': 'Sulfate, Dissolved, as SO4',\n",
    "    'Sulfate, Volatile': 'Sulfate, Volatile, as S',\n",
    "    'Sulfate, InOrganic': 'Sulfate, Total, as S',\n",
    "    'Sulfite, Total': 'Sulfite, Total, as S',\n",
    "    'Sulfite, as SO3': 'Sulfite, Total, as SO3',\n",
    "    'Sulfur': 'Sulfur, Total, as S',\n",
    "    'Sulfur, Total': 'Sulfur, Total, as S',\n",
    "    'Sulfur, Dissolved': 'Sulfur, Dissolved, as S',\n",
    "    'Sulfur, Dissolved, as S': 'Sulfur, Dissolved, as S',\n",
    "    'Temperature, Dissolved': 'Temperature',\n",
    "    'Temperature, Total': 'Temperature',\n",
    "    'Temperature, deg F': 'Temperature',\n",
    "    'Total Solids': 'Solids, Total',\n",
    "    'Total Solids, Total': 'Solids, Total',\n",
    "    'Total Solids, Dissolved': 'Solids, Total Dissolved',\n",
    "    'Total Suspended Solids': 'Solids, Total Suspended',\n",
    "    'Total Suspended Solids, Dissolved': 'Solids, Total Suspended',\n",
    "    'Total Suspended Solids, Total': 'Solids, Total Suspended',\n",
    "    'Total Suspended Solids, as CaCO3': 'Solids, Total Suspended',\n",
    "    'Total Solids, Volatile': 'Solids, Total Volatile',\n",
    "    'Total Volatile Solids': 'Solids, Total Volatile',\n",
    "    'Total Volatile Solids, Dissolved': 'Solids, Total Volatile',\n",
    "    'Total Volatile Solids, Total': 'Solids, Total Volatile',\n",
    "    'Total Volatile Solids, Volatile': 'Solids, Total Volatile',\n",
    "    'Total Suspended Solids, Volatile': 'Solids, Total Volatile Suspended',\n",
    "    'Volatile Suspended Solids': 'Solids, Total Volatile Suspended',\n",
    "    'Volatile Suspended Solids, Dissolved': 'Solids, Total Volatile Suspended',\n",
    "    'Volatile Suspended Solids, Total': 'Solids, Total Volatile Suspended',\n",
    "    'Volatile Suspended Solids, Volatile': 'Solids, Total Volatile Suspended',\n",
    "    'pH, Dissolved': 'pH',\n",
    "    'pH, Total': 'pH',\n",
    "}\n",
    "\n",
    "# Replaced values in 'CharacteristicName' using the mapping\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].replace(replace_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f4ed1a-7463-40ac-bd47-0974d7edbe92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleaned up commas and spaces.\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].str.replace('\\s+', ' ').str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fa01ac-e532-4c01-86bf-e89d1f430340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printed unique 'Parameter' values to check for consistant naming.\n",
    "unique_parameters = sorted(EPA_df['Parameter'].unique())\n",
    "for parameter in unique_parameters:\n",
    "    print(parameter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8cef3a-c7e5-4db5-9e8d-a1c5bda9b160",
   "metadata": {
    "tags": []
   },
   "source": [
    "These all look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc337f7-32d3-4cd4-8a56-58555f6ca85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printed unique 'Parameter' values and original values to check naming.\n",
    "grouped_df = EPA_df.groupby('Parameter').agg({\n",
    "    'ParameterOrig': 'unique'\n",
    "}).reset_index()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de3e7cd-b852-4d85-b036-9ade486aaeb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "These all look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6363e8-e126-4abb-b94c-4b7fb91711a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropped parameter feature as they are no longer needed.\n",
    "features_to_drop = [\n",
    "    'CharacteristicName',\n",
    "    'ResultSampleFractionText',\n",
    "    'MethodSpecificationName'\n",
    "    ]\n",
    "EPA_df.drop(columns=features_to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b7d766-3a2e-48eb-9ee1-308ab4aaeb4b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_05.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9fa677-2f7e-4569-91be-4c7035f75113",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examined results columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922b6b58-055c-4cd1-a51f-c4cd3a3a0cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_05 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_05.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb917-98a6-49a1-a6fe-2a77bb575fe1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Duplicated and combined features related to results so I have information in one place for future reference.\n",
    "EPA_df['ResultOrig'] = (\n",
    "    EPA_df['ResultMeasureValue'].fillna('').astype(str) +\n",
    "    ' ' +\n",
    "    EPA_df['ResultMeasure/MeasureUnitCode'].fillna('') +\n",
    "    ' ' +\n",
    "    EPA_df['MeasureQualifierCode'].fillna('')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8b999a-d2e0-44ec-911f-61ae1f6c58e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted rows where 'MeasureQualifierCode' indicates that the results were rejected, failed, or contaminated by the labratory.\n",
    "\n",
    "# List of conditions to delete\n",
    "conditions_to_delete = ['ISP', 'SCF', 'R', 'FFD', 'N', 'SCX', 'F', 'CON']\n",
    "\n",
    "# Converted 'MeasureQualifierCode' to string and then delete rows where it contains specified conditions as whole words\n",
    "pattern = r'\\b(?:' + '|'.join(conditions_to_delete) + r')\\b'\n",
    "EPA_df = EPA_df[~EPA_df['MeasureQualifierCode'].astype(str).str.contains(pattern, case=False, regex=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5aba44d-49c6-4d9c-8c54-903fb349de85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique data types and their counts to see what's in the results column.\n",
    "\n",
    "# Counted data types\n",
    "data_type_counts = EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the results\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__) == data_type].nunique()\n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b601ed5-61c4-41e5-bb03-b1511f85dcfb",
   "metadata": {
    "tags": []
   },
   "source": [
    "This feature shopuld contain no strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ff15f-21fc-4b41-bc50-8eda183d8563",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values into floats while leaving those that couldn't be converted in place.\n",
    "\n",
    "# Defined function\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        # Tries converting the value to float\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        # If conversion failed, returned the original value\n",
    "        return value\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1be00b9-6e8e-44dc-aba2-1701cb0dc237",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of NaNs in results to see how many of the floats are NaNs.\n",
    "nan_count = EPA_df['ResultMeasureValue'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9013b-a190-469b-94f6-5bfbd606d722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed 100 of the unique string values to see some of the values in reults that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339add79-82f5-4dea-b8ec-2d6d1982edac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if comments will explain the *s.\n",
    "\n",
    "# Selected specific columns\n",
    "selected_columns_df = EPA_df[['ResultMeasureValue', 'ResultLaboratoryCommentText']]\n",
    "\n",
    "# Applied filters for not null 'ResultLaboratoryCommentText' and containing asterisk in 'ResultMeasureValue'\n",
    "filtered_df = selected_columns_df[\n",
    "    (EPA_df['ResultLaboratoryCommentText'].notnull()) &\n",
    "    (EPA_df['ResultMeasureValue'].str.contains('\\*'))\n",
    "]\n",
    "\n",
    "# Printed unique combinations of the two columns\n",
    "unique_combinations = filtered_df.drop_duplicates()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(unique_combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7a95da-7ea9-4d34-b7c9-b1d36f030d91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if an other feature will explain the *s.\n",
    "\n",
    "# Filtered dataframe for floats with *s.\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasureValue'].str.contains('\\*.*\\.', na=False)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d370190f-3c56-4e61-a8da-5f60cad974a7",
   "metadata": {},
   "source": [
    "The comments and other features did not help determine the meaning of the astricks so I assumed the values are fine to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6352d35c-dd36-4b44-b617-c109f84c4190",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed the *s from the values.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: str(x).replace('*', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46bea0-1010-4c36-98a9-d8ac7224608a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique combinations of values in 'ResultMeasureValue' that contain '<' and 'ResultLaboratoryCommentText' to see if the comments explain anything.\n",
    "\n",
    "# Filtered rows where 'ResultMeasureValue' contains '<'\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasureValue'].str.contains('<', case=False, na=False)]\n",
    "\n",
    "# Printed unique and sorted combinations of 'ResultMeasureValue' and 'ResultLaboratoryCommentText'\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'ResultLaboratoryCommentText']].drop_duplicates()\n",
    "unique_combinations = unique_combinations.sort_values(by='ResultMeasureValue')\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['ResultLaboratoryCommentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946799d-caef-47f4-9b2e-629d4ac125aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "No helpful comments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264182b1-89b3-4b64-bf30-4b5ce9c500cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values starting with < to half the value. I am assuming the number is the minimum detection limit (MDL). It's common practice to devide the MDL by two so you have a number for analysis.\n",
    "\n",
    "# Custom function to handle special cases\n",
    "def process_value(value):\n",
    "    if pd.notna(value):\n",
    "        if isinstance(value, str):\n",
    "            if value.startswith('<L'):\n",
    "                # Leave '<L' as is\n",
    "                return value\n",
    "            elif value.startswith('<'):\n",
    "                # Attempt to convert the rest to a float after removing '<'\n",
    "                try:\n",
    "                    return float(value[1:]) / 2\n",
    "                except ValueError:\n",
    "                    # If the conversion fails, return value\n",
    "                    return value\n",
    "            else:\n",
    "                # If the value is a string but doesn't start with '<', return original value\n",
    "                return value\n",
    "        else:\n",
    "            # If the value is not a string, return original value\n",
    "            return value\n",
    "    else:\n",
    "        return value\n",
    "    \n",
    "# Applied the custom function to 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(process_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da0b922-5eae-4af0-a49b-93a7e90ccd51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced \"..\" in string values with \".\". Assumed these are data entry errors.\n",
    "\n",
    "# Defined function\n",
    "def clean_and_convert(value):\n",
    "    if isinstance(value, str):\n",
    "        cleaned_value = value.replace('..', '.')\n",
    "        return cleaned_value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(clean_and_convert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e05286e-1152-4414-9609-5a671b39bbec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values into floats while leaving those that couldn't be converted in place.\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241e6156-a139-4ea0-8154-111a9e105214",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed 100 of the unique string values to see some of the values in reults that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae145b87-d4ae-4f17-aaed-456c9d4dd1d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in the results that contain ':' and their count. \n",
    "detect_values = EPA_df[EPA_df['ResultMeasureValue'].str.contains(':', case=False, na=False)]['ResultMeasureValue'].unique()\n",
    "for value in detect_values:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e2fe74-afca-4428-a206-42b5610839de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if any feature will explain the :s.\n",
    "\n",
    "# Filtered dataframe for :s.\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasureValue'].str.contains(':', na=False)]\n",
    "pd.set_option('display.max_columns', None)\n",
    "filtered_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583dfe58-85d3-4005-9ba5-54d48409909a",
   "metadata": {},
   "source": [
    "It appears that the results that look like times were incorrectly formatted in the source excel book before being uploaded to the EPA database. Therefore, the numbers retained the incorrect time format and I had to convert them back into the correct numbers the same way that Excel changes between time to number formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac52fd-10e2-4567-956d-b28520e1cbb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted string time value to float number.\n",
    "\n",
    "# Custom conversion function for time strings and floats to numbers\n",
    "def convert_value_to_number(value):\n",
    "    try:\n",
    "        if pd.notna(value):\n",
    "            if isinstance(value, str) and ':' in value:\n",
    "                time_obj = pd.to_datetime(value, format='%I:%M:%S %p').time()\n",
    "                return (time_obj.hour * 3600 + time_obj.minute * 60 + time_obj.second) / 86400\n",
    "            else:\n",
    "                return float(value)\n",
    "        else:\n",
    "            return value\n",
    "    except ValueError:\n",
    "        return value\n",
    "\n",
    "# Apply the custom conversion function to 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: convert_value_to_number(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1a9a79-a6ce-44b6-a73b-b31159a5ed50",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed values from 'ResultMeasureValue' containing 'j'.\n",
    "values_with_j = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].astype(str).str.contains('j', case=False, na=False)].tolist()\n",
    "print(values_with_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e2dfb7-e6cd-4df8-92f9-fd8a861dcdc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed 'J' from values in 'ResultMeasureValue'. A 'J' qualifier tupicall means that the result was calculated by the lab rather than directly measured. I'm assuming the data is fine to use.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: str(x).replace('J', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f7c672-5e3b-4e88-8937-f74088d195c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if comments will explain non-numeric results.\n",
    "\n",
    "# Filtered ResultMeasureValue for values not containing any numbers\n",
    "filtered_df = EPA_df[~EPA_df['ResultMeasureValue'].astype(str).str.contains('\\d', case=False, na=False, regex=True)]\n",
    "\n",
    "# Printed unique combinations of ResultMeasureValue and ResultLaboratoryCommentText\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'ResultLaboratoryCommentText']].drop_duplicates().sort_values(by=['ResultMeasureValue', 'ResultLaboratoryCommentText'])\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['ResultLaboratoryCommentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd670f4e-e77b-44b7-9c73-b3e0d15f115e",
   "metadata": {},
   "source": [
    "The comments explained some of the NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bf502e-8194-417c-be77-b4e08ff75f26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced specified values in the 'ResultMeasureValue' column that indicate that the result was below the detection limit with '<L'. This was a place holder for future calcs. \n",
    "values_to_replace = ['<LOD', 'BLD', 'BPQL', 'MDP', 'ND', 'Non-detect', 'Not Detected',\n",
    "                     'Not detected', 'Present <QL', 'Present Below Quantification Limit',\n",
    "                     'Trace', 'Mdp', 'N.d.', 'Nd']\n",
    "\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].replace(values_to_replace, '<L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b70653-57fe-4792-a9fa-0a24c2a614d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced string values without numbers (excluding '<L') with NaN.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: np.nan if pd.isna(x) else (x if any(char.isdigit() for char in str(x)) or '<L' in str(x) else np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84060669-e6e4-4729-9ca1-7d75149bdc58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked incorrectly entered temperatures.\n",
    "\n",
    "# Filtered ResultMeasureValue for values containing \"F\" or \"C\"\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasureValue'].astype(str).str.contains('F|C', case=False, na=False, regex=True)]\n",
    "\n",
    "# Printed unique combinations of ResultMeasureValue and ResultMeasure/MeasureUnitCode\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode']].drop_duplicates().sort_values(by=['ResultMeasureValue', 'ResultMeasure/MeasureUnitCode'])\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['ResultMeasure/MeasureUnitCode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c2eb146-fe99-498c-b7ca-3f35f324d44d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed 'C' to 'F'.\n",
    "\n",
    "# Values to find in 'ResultMeasureValue'\n",
    "values_to_find = ['35 F', '36 F', '39 F', '40 F', '40F', '42 F', '43 F', '45 F', '46 F', '47 F',\n",
    "                  '48 F', '49 F', '50 F', '51 F', '52 F', '53 F', '54 F', '55 F', '56 F', '57 F',\n",
    "                  '58 F', '59 F', '60 F', '63 F', '64 F', '64.5F', '65 F', '66 F', '67 F', '68 F',\n",
    "                  '69 F', '70 F', '71 F', '72 F', '73 F', '74 F', '75 F', '76 F', '77 F', '78 F',\n",
    "                  '79 F', '80 F', '80F', '82F', '94 F']\n",
    "\n",
    "# Replaced the corresponding values in 'ResultMeasure/MeasureUnitCode' with 'deg F'\n",
    "EPA_df.loc[EPA_df['ResultMeasureValue'].isin(values_to_find), 'ResultMeasure/MeasureUnitCode'] = 'deg F'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd437da-b578-4d22-b8ed-e7a0c316e23c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced mis-entered temperature values.\n",
    "\n",
    "values_to_replace = {\n",
    "    '27.4 C': '27.4',\n",
    "    '27.6 C': '27.6',\n",
    "    '28.1 C': '28.1',\n",
    "    '35 F': '35',\n",
    "    '36 F': '36',\n",
    "    '39 F': '39',\n",
    "    '40 F': '40',\n",
    "    '40F': '40',\n",
    "    '42 F': '42',\n",
    "    '43 F': '43',\n",
    "    '45 F': '45',\n",
    "    '46 F': '46',\n",
    "    '47 F': '47',\n",
    "    '48 F': '48',\n",
    "    '49 F': '49',\n",
    "    '50 F': '50',\n",
    "    '51 F': '51',\n",
    "    '52 F': '52',\n",
    "    '53 F': '53',\n",
    "    '54 F': '54',\n",
    "    '55 F': '55',\n",
    "    '56 F': '56',\n",
    "    '57 F': '57',\n",
    "    '58 F': '58',\n",
    "    '59 F': '59',\n",
    "    '60 F': '60',\n",
    "    '63 F': '63',\n",
    "    '64 F': '64',\n",
    "    '64.5F': '64.5',\n",
    "    '65 F': '65',\n",
    "    '66 F': '66',\n",
    "    '67 F': '67',\n",
    "    '68 F': '68',\n",
    "    '69 F': '69',\n",
    "    '70 F': '70',\n",
    "    '71 F': '71',\n",
    "    '72 F': '72',\n",
    "    '73 F': '73',    \n",
    "    '74 F': '74',\n",
    "    '75 F': '75',\n",
    "    '76 F': '76',\n",
    "    '77 F': '77',\n",
    "    '78 F': '78',\n",
    "    '79 F': '79',\n",
    "    '80 F': '80',\n",
    "    '80F': '80', \n",
    "    '82F': '82',\n",
    "    '94 F': '94',\n",
    "}\n",
    "\n",
    "# Replaced the values in 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].replace(values_to_replace, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c16649-8b80-4ccf-8439-ade7521b19d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values into floats while leaving those that couldn't be converted in place.\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ac7974-9ca5-4ae9-b46c-ce52f3baf062",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed 100 of the unique string values to see some of the values in reults that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1eecf4-015a-4718-816d-6e847cdb9be6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_06.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9d03c2-880a-48fa-8917-11d73df6ffbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read EPA_data_06 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bca50b-c313-41c0-9fbe-d417f82712cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contain '>'.\n",
    "unique_values_with_greater = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains('>')].unique()\n",
    "print(list(unique_values_with_greater))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d5c58d-15a7-4786-9235-5f336a322217",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced '>22 (OUT OF PROBE RANGE)' with '>22'.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: str(x).replace('>22 (OUT OF PROBE RANGE)', '22') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0336b1-7736-4030-84d9-8a3b6e05dbd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed '>' from strings that begin with '>'. The real value is larger than the number but I don't know by how much so I defaulted to the minimum.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x[1:] if isinstance(x, str) and x.startswith('>') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015258a-403d-4508-ac60-4c3d416a789d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contain 'Invalid '.\n",
    "unique_values_with_invalid = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains('Invalid ')].unique()\n",
    "print(list(unique_values_with_invalid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e07da9a-5a6a-49a0-a4e0-5a05321a6f74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed 'Invalid ' from strings that contain 'Invalid '. A value was produced so I'll use it.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: str(x).replace('Invalid ', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad54f68-cb3b-4189-b9d4-a72ed7f5ba09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed values that begin with '.'\n",
    "dot_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].str.startswith('.').fillna(False)]\n",
    "print(dot_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb607e24-4d69-4a71-b4aa-95dee5175c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed '.' from strings that begin with '.'. I assumed these to be data entry errors.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x[1:] if isinstance(x, str) and x.startswith('.') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b4ad6e-6c14-4e61-9804-d81c89826796",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed values that end with '.'\n",
    "dot_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].str.endswith('.').fillna(False)]\n",
    "print(dot_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84552228-eebd-462a-9416-69554aef0d6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed '.' from strings that end with '.'.  I assumed these to be data entry errors.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x[:-1] if isinstance(x, str) and x.endswith('.') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbef202-882b-485b-9ba9-1dc1d281873f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contain '='.\n",
    "unique_values_with_equals = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains('=')].unique()\n",
    "print(list(unique_values_with_equals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cdc4dd-eb30-407f-bf71-8df83e61622c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed '=' from strings that begin with '='. I assumed these to be data entry errors.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x[1:] if isinstance(x, str) and x.startswith('=') else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4f3373-67df-47bc-84c2-1fa975a31169",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed 'ND LOD=' and divided number by 2 becasue the number provided is the detection limit.\n",
    "\n",
    "# Custom function to handle special cases\n",
    "def process_value(value):\n",
    "    if pd.notna(value):\n",
    "        if isinstance(value, str):\n",
    "            if value.startswith('ND LOD='):\n",
    "                # Attempt to convert the rest to a float after removing 'ND LOD=' and then divide by 2\n",
    "                try:\n",
    "                    return float(value.replace('ND LOD=', '')) / 2\n",
    "                except ValueError:\n",
    "                    # If the conversion fails, return value\n",
    "                    return value\n",
    "            else:\n",
    "                # If the value is a string but doesn't start with 'ND LOD=', return original value\n",
    "                return value\n",
    "        else:\n",
    "            # If the value is not a string, return original value\n",
    "            return value\n",
    "    else:\n",
    "        return value\n",
    "\n",
    "# Applied the custom function to 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(process_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01b220c-e8f5-4e1c-905f-c5f1ac4e7463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contain ' at  '.\n",
    "unique_values_with_at = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains(' at ', case=False)].unique()\n",
    "print(list(unique_values_with_at))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1853cbe6-8e9c-4d81-8cda-dede3c090f04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed 'at' followed by a number from 'ResultMeasureValue'. This information is not useful.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: re.sub(r'\\s*AT\\s*\\d+', '', str(x)) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f4d975-61a8-463f-8be2-e0c5cae2dda4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contain ','.\n",
    "unique_values_with_comma = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains(',')].unique()\n",
    "print(list(unique_values_with_comma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d217ea-076b-4d22-a94d-23d7a0eebe03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced values with commas. I assume these to be typos.\n",
    "values_to_replace = {\n",
    "    '13,75': '13.75',\n",
    "    '0,09': '0.09',\n",
    "    '3,5': '3.5',\n",
    "    '32,7': '32.7',\n",
    "}\n",
    "\n",
    "# Replaced the values in 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].replace(values_to_replace, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a225fe9-9dd6-4302-a206-27e3898497a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed ',' from strings that contain ','.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x.replace(',', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5bb00b-6919-4ff8-9784-b3e070f0734f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed list of values that contains '[' or ']'.\n",
    "unique_values_with_bracket = EPA_df['ResultMeasureValue'].astype(str)[EPA_df['ResultMeasureValue'].astype(str).str.contains('[\\[\\]]')].unique()\n",
    "print(list(unique_values_with_bracket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b38b70e-feba-4bad-9dab-793b88bce227",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Removed brackets from strings.  I assumed these to be data entry errors.\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(lambda x: x.replace('[', '').replace(']', '') if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dcab9a-0e4b-4f3a-bd4b-249d710ff717",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values into floats while leaving those that couldn't be converted in place.\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9bf362-261f-4702-97a0-aa5827ad584a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed the unique string values to see the rest of the values in reults that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3a5c99-e25a-4296-9d93-95cef869ccd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed remaining string 'ResultMeasureValue' with select other coulumns to see if they can explain the value.\n",
    "selected_columns = [\n",
    "    'ResultDetectionConditionText',\n",
    "    'Parameter',\n",
    "    'ResultMeasureValue',\n",
    "    'ResultMeasure/MeasureUnitCode',\n",
    "    'MeasureQualifierCode',\n",
    "    'ResultAnalyticalMethod/MethodIdentifier',\n",
    "    'ResultLaboratoryCommentText'\n",
    "]\n",
    "\n",
    "# Filtered data\n",
    "filtered_df = EPA_df[EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str) and x != '<L')]\n",
    "filtered_df_selected_columns = filtered_df[selected_columns]\n",
    "\n",
    "# Sorted by 'ResultMeasureValue'\n",
    "sorted_df = filtered_df_selected_columns.sort_values(by='ResultMeasureValue')\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9450f503-d34e-4424-aa3b-ff5d5b783e5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted rows where I could not determine true 'ResultMeasureValue'.\n",
    "values_to_delete = [\"0.002'447.0.0\", \"1300(A)\", \"19-72\", \"300(A)\", \"300(A)0\", \"X2\", \"X3\", \"Z2\", \"86.2%\"]\n",
    "EPA_df = EPA_df[~EPA_df['ResultMeasureValue'].isin(values_to_delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c44cb4-3878-41c3-bd6d-53020c922380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed 'ResultMeasureValue' where I could determine true value.\n",
    "\n",
    "values_to_replace = {\n",
    "    '0.014mg/L': '0.014', # Correct units already in data \n",
    "    '0.94mg/L': '0.94', # Correct units already in data \n",
    "    '1.14mg/L': '1.14', # Correct units already in data \n",
    "    '1.15µg/L': '1.15', # Correct units already in data \n",
    "    '10-15': '12.5', # Took mean of range\n",
    "    '11.\\n11.8': '11.8', # Value make sense for parameter\n",
    "    '12 9': '12.9', # Value with decimal make sense for parameter\n",
    "    '12/31/1899 5:52:48 AM': '1.25', # Format change\n",
    "    '12/31/1899 9:04:00 AM': '1.38', # Format change\n",
    "    '136.44% 12.134 mg': '12.134', # Kept DO in mg to match units\n",
    "    '148`': '148', # Assumed to be a typo\n",
    "    '16:19:12': '15.67', # Took mean of range\n",
    "    '20\\+': '20', # Assumed to be a typo\n",
    "    '21.9\\n21.9': '21.9', # Value make sense for parameter\n",
    "    '21/1': '21.1', # Value make sense for parameter\n",
    "    '22.56-23.89': '23.225', # Took mean of range\n",
    "    '23.3\\n23.3': '23.3', # Value make sense for parameter\n",
    "    '23.6\\n23.6': '23.6', # Value make sense for parameter\n",
    "    '2O2': '202', # Assumed to be a typo\n",
    "    '36\\n36': '36', # Value make sense for parameter\n",
    "    '4.8\\n4.8': '4.8', # Value make sense for parameter\n",
    "    '5 .9': '5.9', # Assumed to be a typo\n",
    "    '6\\n6': '6', # Value make sense for parameter\n",
    "    '6.4\\n6.4': '6.4', # Value make sense for parameter\n",
    "    '60.26% 5.85 mg': '5.85', # Kept DO in mg to match units\n",
    "    '7\\n27.2': '27.2', # Value make sense for parameter\n",
    "    '7.27.4': '7.3', # Took mean of range\n",
    "    '7.57.2': '7.35', # Took mean of range\n",
    "    '7.77.3': '7.5', # Took mean of range\n",
    "    '75.5% 8.06mg/l': '8.06', # Kept DO in mg to match units\n",
    "    '79.6% 6.69 mg': '6.69', # Kept DO in mg to match units\n",
    "    '8.48\\+': '8.48', # Assumed to be a typo\n",
    "    'E11.4': '11.4', # Assumed to be a typo\n",
    "    'O.3': '0.3', # Assumed to be a typo\n",
    "}\n",
    "\n",
    "# Replace the values in 'ResultMeasureValue'\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].replace(values_to_replace, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed9d2b-14fa-4c71-8344-c33cbe787622",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values into floats while leaving those that couldn't be converted in place.\n",
    "\n",
    "# Applied function\n",
    "EPA_df['ResultMeasureValue'] = EPA_df['ResultMeasureValue'].apply(convert_to_float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6965fbe3-ed59-4933-848f-c11a912a507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printed the unique string values to see the rest of the values in reults that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43d0639-b36f-4bfc-a313-58c2a09ab068",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of NaNs in results.\n",
    "nan_count = EPA_df['ResultMeasureValue'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ea609-0126-401f-8437-cb7da6258490",
   "metadata": {
    "tags": []
   },
   "source": [
    "Need to fill in the 'ResultMeasureValue' NaNs with values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87297c96-d5c4-4014-9b67-336b862e0687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if 'ResultDetectionConditionText' will explain non-numeric results.\n",
    "\n",
    "# Filter ResultMeasureValue for values not containing any numbers\n",
    "filtered_df = EPA_df[~EPA_df['ResultMeasureValue'].astype(str).str.contains('\\d', case=False, na=False, regex=True)]\n",
    "\n",
    "# Print unique combinations of ResultMeasureValue and ResultDetectionConditionText\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'ResultDetectionConditionText']].drop_duplicates().sort_values(by=['ResultMeasureValue', 'ResultDetectionConditionText'])\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['ResultDetectionConditionText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1cdc3-70b7-4cda-bcca-aa7f13be29d9",
   "metadata": {
    "tags": []
   },
   "source": [
    "Yes, 'ResultDetectionConditionText' will explain some non-numeric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e009ba-ed6c-4777-962e-9cdbcfeaaa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced NaNs in 'ResultMeasureValue' with '<L' for values from 'ResultDetectionConditionText' that all mean less than limit. '<L' is a place holder for future calculation.\n",
    "\n",
    "# List of conditions\n",
    "conditions = [\n",
    "    'Present Below Quantification Limit',\n",
    "    'Not Detected',\n",
    "    'Below Method Detection Limit',\n",
    "    'Detected Not Quantified',\n",
    "    'Below Detection Limit',\n",
    "    '*Non-detect',\n",
    "    '*NOT DETECTED',\n",
    "    '*Present <QL',\n",
    "    'Not Detected at Reporting Limit',\n",
    "    'Below Reporting Limit',\n",
    "    '*Present < QL',\n",
    "    '*Present<QL',\n",
    "    '*Present',\n",
    "    'Not Detected at Detection Limit'\n",
    "]\n",
    "\n",
    "# Filled NaN values in 'ResultMeasureValue' based on the specified conditions\n",
    "EPA_df['ResultMeasureValue'] = np.where(\n",
    "    EPA_df['ResultMeasureValue'].isna() & EPA_df['ResultDetectionConditionText'].isin(conditions),\n",
    "    '<L',\n",
    "    EPA_df['ResultMeasureValue']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aa6667-b440-4a9e-bc95-c2043dc4a65d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if 'MeasureQualifierCode' will explain non-numeric results.\n",
    "\n",
    "# Filtered ResultMeasureValue for values not containing any numbers\n",
    "filtered_df = EPA_df[~EPA_df['ResultMeasureValue'].astype(str).str.contains('\\d', case=False, na=False, regex=True)]\n",
    "\n",
    "# Printed unique combinations of ResultMeasureValue and MeasureQualifierCode\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'MeasureQualifierCode']].drop_duplicates().sort_values(by=['ResultMeasureValue', 'MeasureQualifierCode'])\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['MeasureQualifierCode'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69adb068-756c-4191-bde2-8ab4ac65164a",
   "metadata": {
    "tags": []
   },
   "source": [
    "Yes, 'MeasureQualifierCode' will explain some non-numeric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9319f36-7698-4d46-b5dc-cea04ca986c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced NaNs in 'ResultMeasureValue' with '<L' for values from 'MeasureQualifierCode' that all mean less than limit. '<L' was a place holder for future calculation.\n",
    "\n",
    "# List of conditions to fill NaN values with '<L'\n",
    "conditions_to_fill = ['J', 'B', 'I', 'Q', 'R', 'D', 'DL', 'FDL']\n",
    "\n",
    "# Filled NaN values in 'ResultMeasureValue' with '<L' when 'MeasureQualifierCode' contains specified conditions\n",
    "pattern = r'\\b(?:' + '|'.join(conditions_to_fill) + r')\\b'\n",
    "EPA_df['ResultMeasureValue'] = np.where(\n",
    "    EPA_df['ResultMeasureValue'].isna() & EPA_df['MeasureQualifierCode'].astype(str).str.contains(pattern, case=False, regex=True),\n",
    "    '<L',\n",
    "    EPA_df['ResultMeasureValue']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da21d12b-2ada-41c5-a1bc-848f34e0b9ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Checked to see if comments will explain non-numeric results.\n",
    "\n",
    "# Filtered ResultMeasureValue for values not containing any numbers\n",
    "filtered_df = EPA_df[~EPA_df['ResultMeasureValue'].astype(str).str.contains('\\d', case=False, na=False, regex=True)]\n",
    "\n",
    "# Printed unique combinations of ResultMeasureValue and ResultLaboratoryCommentText\n",
    "unique_combinations = filtered_df[['ResultMeasureValue', 'ResultLaboratoryCommentText']].drop_duplicates().sort_values(by=['ResultMeasureValue', 'ResultLaboratoryCommentText'])\n",
    "\n",
    "for index, row in unique_combinations.iterrows():\n",
    "    print(row['ResultMeasureValue'], row['ResultLaboratoryCommentText'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5511a4-b626-4d5a-8ced-0a8672f9bf6d",
   "metadata": {},
   "source": [
    "Yes, 'ResultLaboratoryCommentText' will explain some non-numeric results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137b37a8-922d-4c85-83c0-4f52e7adf9bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced NaNs in 'ResultMeasureValue' with '<L' for values from 'ResultLaboratoryCommentText' that all mean less than limit. '<L' was a place holder for future calculation.\n",
    "mask = EPA_df['ResultLaboratoryCommentText'].str.contains('below', case=False, na=False)\n",
    "EPA_df.loc[mask, 'ResultMeasureValue'].fillna('<L', inplace=True)\n",
    "EPA_df['ResultMeasureValue'].replace({None: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121d079b-6ed9-4e24-a217-81507cd98e47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique data types and their counts to see what's in the results column.\n",
    "\n",
    "# Counted data types\n",
    "data_type_counts = EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the results\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__) == data_type].nunique()\n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a291f45a-b384-4b25-b92b-1696bbc45624",
   "metadata": {},
   "source": [
    "Now all infomation about results below detection limit are in the results column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a039086-7912-43c7-80d9-b7704c13d667",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of NaNs in results.\n",
    "nan_count = EPA_df['ResultMeasureValue'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b14a92-f55c-493a-90a9-0ba9b1cd05d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed the unique string values to see the rest of the values in results that need to be fixed.\n",
    "unique_string_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: isinstance(x, str))].unique()\n",
    "print(unique_string_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb531e6-f24f-40dd-8ae8-7fa3e2428167",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted all rows where the result is NaN. Nothing else can be done to fill in these values so the rows are not useful.\n",
    "EPA_df = EPA_df.dropna(subset=['ResultMeasureValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87155efc-a0be-411b-9f6e-09d197c65483",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_07.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99f6b92-09ed-444e-9d42-ed388215ae00",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Examined units column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ecb58d-ee3b-4735-8478-be523c2eb168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read EPA_data_07 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_07.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7ac422-d492-45e6-a106-8424ca499be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced 'ResultMeasure/MeasureUnitCode' with NaN when 'ResultMeasureValue' is NaN or '<L'. Having units are pointless when there is no result value.\n",
    "mask = EPA_df['ResultMeasureValue'].isna() | (EPA_df['ResultMeasureValue'] == '<L')\n",
    "EPA_df.loc[mask, 'ResultMeasure/MeasureUnitCode'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b6d10-a5ee-47be-b43c-26d924d50499",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique values in 'ResultDepthHeightMeasure/MeasureUnitCode' to list all units.\n",
    "unique_values_list = sorted(map(str, EPA_df['ResultMeasure/MeasureUnitCode'].unique()))\n",
    "for value in unique_values_list:\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db0b324-f0d7-4cc5-9ac4-baedfdf34393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced mis-entered and equivalent units for consistancey.\n",
    "\n",
    "values_to_replace = {\n",
    "    'mg/l': 'mg/L',\n",
    "    'mg/l as N': 'mg/L',\n",
    "    'mg/l asNO2': 'mg/L',\n",
    "    'mg/l asNO3': 'mg/L',\n",
    "    'mg/l as P': 'mg/L',\n",
    "    'mg/l asPO4': 'mg/L',\n",
    "    'mg/l CaCO3': 'mg/L',\n",
    "    'mg/l CaCO3**': 'mg/L',\n",
    "    'mg/l NH4': 'mg/L',\n",
    "    'mg/l NO3': 'mg/L',\n",
    "    'mg/l PO4': 'mg/L',\n",
    "    'mg N/l******': 'mg/L',\n",
    "    'ug/l': 'ug/L',\n",
    "    'ug/l as P': 'ug/L',\n",
    "    'ug/L as P': 'ug/L',\n",
    "    'uS/cm @25C': 'uS/cm',\n",
    "    '% saturatn**': '%',\n",
    "    'ppm': 'mg/L',\n",
    "    'ppb': 'ug/L',\n",
    "    'ppt': 'ng/L',\n",
    "    'mg/kg': 'mg/L',\n",
    "    'mg/g': 'g/L',\n",
    "    'uS/cm': 'umho/cm',\n",
    "    'mg/m3': 'ug/L',\n",
    "    'mg/m2': 'm3',\n",
    "    '% by wt': '%',\n",
    "    '% solids': '%',\n",
    "    'nu': 'std units',\n",
    "    'units/cm': 'std units',\n",
    "}\n",
    "\n",
    "# Iterated through the dictionary and replace values based on exact matches\n",
    "for value, replacement in values_to_replace.items():\n",
    "    EPA_df.loc[EPA_df['ResultMeasure/MeasureUnitCode'] == value, 'ResultMeasure/MeasureUnitCode'] = replacement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d990c1a-2dc9-46cb-8ca3-f265d873ac12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed information about each unit to help decide how they should be edited.\n",
    "for parameter_value in EPA_df['Parameter'].unique():\n",
    "    subset_df = EPA_df[EPA_df['Parameter'] == parameter_value]\n",
    "    unit_counts = subset_df['ResultMeasure/MeasureUnitCode'].value_counts()\n",
    "    \n",
    "    print(f\"Parameter: {parameter_value}\")\n",
    "    \n",
    "    for unit_code, count in unit_counts.items():\n",
    "        values_numeric = pd.to_numeric(subset_df[subset_df['ResultMeasure/MeasureUnitCode'] == unit_code]['ResultMeasureValue'], errors='coerce')\n",
    "        min_val = values_numeric.min()\n",
    "        max_val = values_numeric.max()\n",
    "        median_val = values_numeric.median()\n",
    "        \n",
    "        print(f\"  Unit: {unit_code}\")\n",
    "        print(f\"    Count: {count}\")\n",
    "        print(f\"    Minimum: {min_val}\")\n",
    "        print(f\"    Maximum: {max_val}\")\n",
    "        print(f\"    Median: {median_val}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa78fd4-de5f-4d45-97af-33d8529556d7",
   "metadata": {
    "tags": []
   },
   "source": [
    "Many units don't match the parameter and need to be changed of deleted. Also, many need to be converted to another unit. Many units have a low count and don't make sense for their respective parameter or aren't worth the effort to edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afbe157-09de-4bc0-b2e6-8dff00e0eb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted rows for units counts equal to or less than 10.\n",
    "\n",
    "# Iterated through unique parameter values\n",
    "for parameter_value in EPA_df['Parameter'].unique():\n",
    "    \n",
    "    # Created a subset DataFrame for the current parameter\n",
    "    subset_df = EPA_df[EPA_df['Parameter'] == parameter_value]\n",
    "    \n",
    "    # Calculated the count of each unit code in the 'ResultMeasure/MeasureUnitCode' column\n",
    "    unit_counts = subset_df['ResultMeasure/MeasureUnitCode'].value_counts()\n",
    "    \n",
    "    # Got unit codes with count <= 10\n",
    "    units_to_delete = unit_counts[unit_counts <= 10].index\n",
    "    \n",
    "    # Identified rows to delete\n",
    "    rows_to_delete = subset_df[subset_df['ResultMeasure/MeasureUnitCode'].isin(units_to_delete)].index\n",
    "    \n",
    "    # Checked if there are rows to delete\n",
    "    if not rows_to_delete.empty:\n",
    "        # Delete the rows from the DataFrame\n",
    "        EPA_df.drop(rows_to_delete, inplace=True)\n",
    "        \n",
    "    # Ran checkpoints for debugging\n",
    "    print(f\"Processing parameter: {parameter_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20255fa-1ee9-42be-a402-e0703305e848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_08.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8301e526-b6b9-4512-a340-31d56a552fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read EPA_data_08 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_08.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85f562-0beb-4179-bc53-f6fdcc745eeb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixed a parameter naming error I missed before.\n",
    "EPA_df['Parameter'] = EPA_df['Parameter'].replace('Dissolved Oxygen Saturation', 'Dissolved Oxygen, Saturation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab497577-0810-468d-ab71-0200550f1bda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixed dissolved oxygen naming errors I missed before.\n",
    "condition = (EPA_df['Parameter'] == 'Dissolved Oxygen') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%')\n",
    "EPA_df.loc[condition, 'Parameter'] = 'Dissolved Oxygen, Saturation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bda1a9-cf48-4287-9025-7669eb6cb61f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fixed dissolved oxygen naming errors I missed before.\n",
    "condition = (EPA_df['Parameter'] == 'Dissolved Oxygen, Saturation') & (EPA_df['ResultMeasure/MeasureUnitCode'] == 'mg/L')\n",
    "EPA_df.loc[condition, 'Parameter'] = 'Dissolved Oxygen'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d49b9f1f-8de3-4c6a-b23d-afc578a241fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted an unneeded parameter I missed before.\n",
    "EPA_df.drop(EPA_df[EPA_df['Parameter'] == 'Light, Transmissivity'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8ab1e-ffb6-4a44-8b62-5651cd4b5c58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted rows with units for specific parameters.\n",
    "conditions = (\n",
    "    (EPA_df['Parameter'] == 'Temperature') & (EPA_df['ResultMeasure/MeasureUnitCode'] == 'ft') | # This unit doesn't make sense and values don't match for parameter.\n",
    "    (EPA_df['Parameter'] == 'Temperature') & (EPA_df['ResultMeasure/MeasureUnitCode'] == 'm') | # This unit doesn't make sense and values don't match for parameter.\n",
    "    (EPA_df['Parameter'] == 'Nitrogen, Total, as N') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') | # This unit doesn't make sense and values don't match for parameter.\n",
    "    (EPA_df['Parameter'] == 'Chlorophyll a, Total') & (EPA_df['ResultMeasure/MeasureUnitCode'] == 'volts') | # This unit doesn't make sense and values don't match for parameter.\n",
    "    (EPA_df['Parameter'] == 'pH') & (EPA_df['ResultMeasure/MeasureUnitCode'] == 'mV') | # Don't have information to create a calibration curve needed for conversion to standard units.\n",
    "    (EPA_df['Parameter'] == 'Solids, Total Suspended') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') | # Don't know volume of water for conversion to mg/L.\n",
    "    (EPA_df['Parameter'] == 'Solids, Total Volatile Suspended') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') | # Don't know volume of water for conversion to mg/L.\n",
    "    (EPA_df['Parameter'] == 'Solids, Total Volatile') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') | # Don't know volume of water for conversion to mg/L.\n",
    "    (EPA_df['Parameter'] == 'Solids, Total') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') | # Don't know volume of water for conversion to mg/L.\n",
    "    (EPA_df['Parameter'] == 'Carbon, Total') & (EPA_df['ResultMeasure/MeasureUnitCode'] == '%') # Don't know volume of water for conversion to mg/L.\n",
    ")\n",
    "\n",
    "EPA_df = EPA_df.loc[~conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d0291a-4b21-418c-affa-cf7f78c89e5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Deleted rows with specific units.\n",
    "units_to_delete = [\n",
    "   'tons/day', # Don't know flow rate for conversion to mg/L.\n",
    "    'FNU', # Can't be converted to mg/L.\n",
    "    'kg', # Don't know volume of water for conversion to mg/L.\n",
    "    'gpg', # Unknown unit\n",
    "    'RFU', # Don't know calibration coefficients from calibration curve for conversion to mg/L.\n",
    "    '#/L', # Don't know chlorophyll-a concentration per cell or conversion to mg/L.\n",
    "    'IVFU', # Don't know calibration coefficients from calibration curve for conversion to mg/L.\n",
    "    'umol', # Don't know volume of water for conversion to mg/L.\n",
    "    'g', # Don't know volume of water for conversion to mg/L.\n",
    "    'm3' # Don't know weight for conversion to mg/L.\n",
    "]\n",
    "EPA_df = EPA_df.loc[~EPA_df['ResultMeasure/MeasureUnitCode'].isin(units_to_delete)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d05bdb-c542-42cf-809f-8dd13f84e702",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed unit names for specific parameters. The original unit did not make sense for the parameter but the values alligned with the new unit.\n",
    "\n",
    "# Dictionary mapping conditions to the desired changes\n",
    "conditions = {\n",
    "    ('Temperature', 'mg/L'): ('deg C',),\n",
    "    ('pH', 'umho/cm'): ('std units',),\n",
    "    ('pH', 'mg/L'): ('std units',),\n",
    "    ('Dissolved Oxygen', 'umho/cm'): ('mg/L',),\n",
    "    ('Dissolved Oxygen', 'ug/L'): ('mg/L',),\n",
    "    ('Dissolved Oxygen', 'cm3/L'): ('mg/L',),\n",
    "    ('Conductivity, Total', 'mg/L'): ('umho/cm',),\n",
    "    ('Conductivity, Total', 'ug/L'): ('umho/cm',),\n",
    "    ('Conductivity, Total', 'std units'): ('umho/cm',),\n",
    "    ('Conductivity, Total', 'umho'): ('umho/cm',),\n",
    "    ('Oxidation Reduction Potential (ORP), Total', 'mg/L'): ('volts',)\n",
    "}\n",
    "\n",
    "# Applied changes using conditions\n",
    "for (param, unit), (new_unit,) in conditions.items():\n",
    "    mask = (EPA_df['Parameter'] == param) & (EPA_df['ResultMeasure/MeasureUnitCode'] == unit)\n",
    "    EPA_df.loc[mask, 'ResultMeasure/MeasureUnitCode'] = new_unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed81d661-1458-4d21-a88a-4bc9bf92b95a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Changed unit names. The original unit did not make sense for any parameter with which it was associated but the values alligned with the new unit.\n",
    "\n",
    "# Mapping of values to be replaced\n",
    "replace_mapping = {\n",
    "    'Deg': 'deg C',\n",
    "    'count': 'std units',\n",
    "    'Mole/L': 'std units',\n",
    "    'mg': 'mg/L',\n",
    "    'm/y': 'mV',\n",
    "    'S/m': 'umho/cm'\n",
    "}\n",
    "\n",
    "# Applied replacements in the DataFrame\n",
    "EPA_df['ResultMeasure/MeasureUnitCode'] = EPA_df['ResultMeasure/MeasureUnitCode'].replace(replace_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6902e7-daeb-4d33-8b75-c7bdc0c6e55e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values and units for specific parameters to correct values and units.\n",
    "\n",
    "# Function to convert 'Chloride, Dissolved' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_chloride_dissolved(umol_per_L):\n",
    "    return umol_per_L * 35.453\n",
    "\n",
    "# Function to convert 'Nitrogen, Dissolved, as N' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrogen_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.1401\n",
    "\n",
    "# Function to convert 'Nitrogen (NO2 & NO3), Dissolved, as N' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_NO2NO3_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.1401\n",
    "\n",
    "# Function to convert 'Sulfate, Dissolved, as S' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_sulfate_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.3207\n",
    "\n",
    "# Function to convert 'Nitrate (NO3), Dissolved, as N' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrate_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.1401\n",
    "\n",
    "# Function to convert 'Nitrogen (NO2, NO3, & NH3), Total, as N' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrogen_total_as_N(umol_per_L):\n",
    "    return umol_per_L * 0.1401\n",
    "\n",
    "# Function to convert 'Ammonia (NH3), Dissolved, as NH3' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_ammonia_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.17031\n",
    "\n",
    "# Function to convert 'Nitrite (NO2), Dissolved, as NO2' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrite_dissolved(umol_per_L):\n",
    "    return umol_per_L * 0.46005\n",
    "\n",
    "# Function to convert 'Nitrate (NO3), Dissolved, as NO3' from umol/L to mg/L. Used parameter molecular weight but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrate_dissolved_as_N(umol_per_L):\n",
    "    return umol_per_L * 0.620049\n",
    "\n",
    "# Function to convert 'Chloride, Dissolved' from mmol/L to mg/L. Used parameter molecular weight but modified milli to produce values that made sense.\n",
    "def convert_chloride_dissolved_mmol(mmol_per_L):\n",
    "    return mmol_per_L * 0.35453\n",
    "\n",
    "# Function to convert 'Chloride, Total' from ueq/L to mg/L. Used parameter molecular weight divided by it's valence but modified micro and milli to produce values that made sense.\n",
    "def convert_chloride_total_ueq(ueq_per_L):\n",
    "    return ueq_per_L * 0.35453 / 1\n",
    "\n",
    "# Function to convert 'Chloride, Dissolved' from ueq/L to mg/L. Used parameter molecular weight divided by it's valence but modified micro and milli to produce values that made sense.\n",
    "def convert_chloride_dissolved_ueq(ueq_per_L):\n",
    "    return ueq_per_L * 35.453 / 1\n",
    "\n",
    "# Function to convert 'Alkalinity, Total, as CaCO3' from ueq/L to mg/L. Used parameter molecular weight divided by it's valence times 2 for carbonate and bicarbonate contributions but modified micro and milli to produce values that made sense.\n",
    "def convert_alkalinity_total(ueq_per_L):\n",
    "    return ueq_per_L * 0.61006 / 1 * 2\n",
    "\n",
    "# Function to convert 'Sulfate, Dissolved, as SO4' from ueq/L to mg/L. Used parameter molecular weight divided by it's valence but modified micro and milli to produce values that made sense.\n",
    "def convert_sulfate_dissolved_so4(ueq_per_L):\n",
    "    return ueq_per_L * 0.960636 / 2\n",
    "\n",
    "# Function to convert 'Nitrate (NO3), Total, as NO3' from ueq/L to mg/L. Used parameter molecular weight divided by it's valence but modified micro and milli to produce values that made sense.\n",
    "def convert_nitrate_total_as_NO3(ueq_per_L):\n",
    "    return ueq_per_L * 0.620045 / 1\n",
    "\n",
    "# Dictionary mapping parameters to conversion functions and new unit codes\n",
    "conversion_functions = {\n",
    "    'Chloride, Dissolved': (convert_chloride_dissolved, 'mg/L'),\n",
    "    'Nitrogen, Dissolved, as N': (convert_nitrogen_dissolved, 'mg/L'),\n",
    "    'Nitrogen (NO2 & NO3), Dissolved, as N': (convert_NO2NO3_dissolved, 'mg/L'),\n",
    "    'Sulfate, Dissolved, as S': (convert_sulfate_dissolved, 'mg/L'),\n",
    "    'Nitrate (NO3), Dissolved, as N': (convert_nitrate_dissolved, 'mg/L'),\n",
    "    'Ammonia (NH3), Dissolved, as NH3': (convert_ammonia_dissolved, 'mg/L'),\n",
    "    'Nitrite (NO2), Dissolved, as NO2': (convert_nitrite_dissolved, 'mg/L'),\n",
    "    'Nitrate (NO3), Dissolved, as NO3': (convert_nitrate_dissolved_as_N, 'mg/L'),\n",
    "    'Nitrogen (NO2, NO3, & NH3), Total, as N': (convert_nitrogen_total_as_N, 'mg/L'),\n",
    "    'Chloride, Dissolved': (convert_chloride_dissolved_mmol, 'mg/L'),\n",
    "    'Chloride, Total': (convert_chloride_total_ueq, 'mg/L'),\n",
    "    'Chloride, Dissolved': (convert_chloride_dissolved_ueq, 'mg/L'),\n",
    "    'Alkalinity, Total, as CaCO3': (convert_alkalinity_total, 'mg/L'),\n",
    "    'Sulfate, Dissolved, as SO4': (convert_sulfate_dissolved_so4, 'mg/L'),\n",
    "    'Nitrate (NO3), Total, as NO3': (convert_nitrate_total_as_NO3, 'mg/L')\n",
    "}\n",
    "\n",
    "# Applied conversions to the DataFrame\n",
    "for parameter, (conversion_function, new_unit_code) in conversion_functions.items():\n",
    "    mask = EPA_df['Parameter'] == parameter\n",
    "    numeric_mask = pd.to_numeric(EPA_df.loc[mask, 'ResultMeasureValue'], errors='coerce').notna()\n",
    "    \n",
    "    # Handled \"<L\" values separately\n",
    "    below_limit_mask = EPA_df.loc[mask, 'ResultMeasureValue'] == '<L'\n",
    "    \n",
    "    # Stored original unit codes for comparison\n",
    "    original_unit_codes = EPA_df.loc[mask, 'ResultMeasure/MeasureUnitCode'].copy()\n",
    "    \n",
    "    # Applied the conversion function to numeric values\n",
    "    converted_values = pd.to_numeric(EPA_df.loc[mask & ~below_limit_mask, 'ResultMeasureValue'], errors='coerce').apply(conversion_function)\n",
    "    \n",
    "    # Checked if conversion occurred and update the values and unit code accordingly\n",
    "    conversion_occurred_mask = ~pd.isna(converted_values)\n",
    "    EPA_df.loc[mask & ~below_limit_mask, 'ResultMeasureValue'] = converted_values[conversion_occurred_mask]\n",
    "    EPA_df.loc[mask & conversion_occurred_mask, 'ResultMeasure/MeasureUnitCode'] = new_unit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d43b528-e2aa-40d3-b0e6-389c2d850d56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Converted values and units to correct values and units.\n",
    "\n",
    "# Conversion functions\n",
    "def convert_degF_to_degC(degF):\n",
    "    return (degF - 32) * 5.0/9.0\n",
    "\n",
    "def convert_ugL_to_mgL(ugL):\n",
    "    return ugL / 1000.0\n",
    "\n",
    "def convert_volts_to_mV(volts):\n",
    "    return volts * 1000.0\n",
    "\n",
    "def convert_mS_cm_to_umho_cm(mS_cm):\n",
    "    return mS_cm * 1000.0\n",
    "\n",
    "def convert_S_m_to_umho_cm(S_m):\n",
    "    return S_m * 1000000.0\n",
    "\n",
    "def convert_mho_cm_to_umho_cm(mho_cm):\n",
    "    return mho_cm * 1000.0\n",
    "\n",
    "def convert_mmhos_cm_to_umho_cm(mmhos_cm):\n",
    "    return mmhos_cm * 1000.0\n",
    "\n",
    "def convert_mS_m_to_umho_cm(mS_m):\n",
    "    return mS_m * 1000.0\n",
    "\n",
    "def convert_ft_to_m(ft):\n",
    "    return ft * 0.3048\n",
    "\n",
    "def convert_in_to_m(inch):\n",
    "    return inch * 0.0254\n",
    "\n",
    "# Dictionary mapping units to conversion functions\n",
    "conversion_functions = {\n",
    "    'deg F': (convert_degF_to_degC, 'deg C'),\n",
    "    'ug/L': (convert_ugL_to_mgL, 'mg/L'),\n",
    "    'volts': (convert_volts_to_mV, 'mV'),\n",
    "    'mS/cm': (convert_mS_cm_to_umho_cm, 'umho/cm'),\n",
    "    'S/m': (convert_S_m_to_umho_cm, 'umho/cm'),\n",
    "    'mho/cm': (convert_mho_cm_to_umho_cm, 'umho/cm'),\n",
    "    'mmhos/cm': (convert_mmhos_cm_to_umho_cm, 'umho/cm'),\n",
    "    'mS/m': (convert_mS_m_to_umho_cm, 'umho/cm'),\n",
    "    'ft': (convert_ft_to_m, 'm'),\n",
    "    'in': (convert_in_to_m, 'm')\n",
    "}\n",
    "\n",
    "# Conversion functions\n",
    "def convert_with_handling(value, conversion_function):\n",
    "    try:\n",
    "        return conversion_function(float(value))\n",
    "    except ValueError:\n",
    "        return value  # Return as is for non-numeric values\n",
    "\n",
    "# Apply conversions to the DataFrame\n",
    "for unit_code, (conversion_function, new_unit_code) in conversion_functions.items():\n",
    "    if unit_code == '<L':\n",
    "        continue  # Skip conversion for '<L'\n",
    "\n",
    "    mask = EPA_df['ResultMeasure/MeasureUnitCode'] == unit_code\n",
    "    EPA_df.loc[mask, 'ResultMeasureValue'] = EPA_df.loc[mask, 'ResultMeasureValue'].apply(lambda x: convert_with_handling(x, conversion_function))\n",
    "    EPA_df.loc[mask, 'ResultMeasure/MeasureUnitCode'] = new_unit_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44112d66-32e4-4017-9eb8-76a0beef78df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reprinted information about each unit to confirm changes.\n",
    "for parameter_value in EPA_df['Parameter'].unique():\n",
    "    subset_df = EPA_df[EPA_df['Parameter'] == parameter_value]\n",
    "    unit_counts = subset_df['ResultMeasure/MeasureUnitCode'].value_counts()\n",
    "    \n",
    "    print(f\"Parameter: {parameter_value}\")\n",
    "    \n",
    "    for unit_code, count in unit_counts.items():\n",
    "        values_numeric = pd.to_numeric(subset_df[subset_df['ResultMeasure/MeasureUnitCode'] == unit_code]['ResultMeasureValue'], errors='coerce')\n",
    "        min_val = values_numeric.min()\n",
    "        max_val = values_numeric.max()\n",
    "        median_val = values_numeric.median()\n",
    "        \n",
    "        print(f\"  Unit: {unit_code}\")\n",
    "        print(f\"    Count: {count}\")\n",
    "        print(f\"    Minimum: {min_val}\")\n",
    "        print(f\"    Maximum: {max_val}\")\n",
    "        print(f\"    Median: {median_val}\")\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6023d829-2583-44cf-a52b-ff0bcd3c6ec8",
   "metadata": {},
   "source": [
    "Looks good. All parameters have one unit (except for those where all results ar '<L') and that unit is appropriate for the parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44502fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data_09.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c894b1f-b8ca-4a57-8ede-b014c91e294c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Imputed half detection levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6e1b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read EPA_data_09 file into pandas DataFrame.\n",
    "EPA_df = pd.read_csv('/Users/carahcampini/Desktop/Capstone/Edited_Data/EPA_data_09.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381d6202-2403-4ba7-b032-ba26ced2ceb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Counted number of '<L' values in resluts.\n",
    "count_of_L_values = EPA_df['ResultMeasureValue'].str.count('<L').sum()\n",
    "print(count_of_L_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14f98cd-f923-42f1-9bcb-79db180dc52d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Replaced '<L' result, which denoted results that were less than the detection limit, with half the value of the minimum result for their respective parameter. Standard practice is to impute half of the minimum detection value but I do not have that information.\n",
    "\n",
    "# Convert 'ResultMeasureValue' to numeric, ignoring errors to handle '<L'\n",
    "EPA_df['ResultMeasureValue'] = pd.to_numeric(EPA_df['ResultMeasureValue'], errors='coerce')\n",
    "\n",
    "# Find the minimum values for each unique 'Parameter'\n",
    "min_values = EPA_df.groupby('Parameter')['ResultMeasureValue'].min()\n",
    "\n",
    "# Replace '<L' with half the respective minimum value\n",
    "for parameter, min_value in min_values.items():\n",
    "    mask = (EPA_df['Parameter'] == parameter) & (EPA_df['ResultMeasureValue'].isna())\n",
    "    EPA_df.loc[mask, 'ResultMeasureValue'] = min_value / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70741b9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Counted number of NaNs in results.\n",
    "nan_count = EPA_df['ResultMeasureValue'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63e6e57-51fe-40b5-96f4-3eea94b4c009",
   "metadata": {},
   "source": [
    "The code to replace '<L' with half the minimum value skipped the 8 parameters where all 'ResultMeasureValue' were '<L'. The '<L' was, however, changed to NaN. As this only occured 219 times, occured for only 8 parameters (none of which are the more critical parameters), and I do not have the information to impute values, I will delete these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd919925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deleted all rows where the result is NaN. Nothing else can be done to fill in these values so the rows are not useful.\n",
    "EPA_df = EPA_df.dropna(subset=['ResultMeasureValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9214b49-bb7a-44c3-8a9c-b5e2c2263771",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Printed unique data types and their counts to see what's in the results column.\n",
    "\n",
    "# Counted data types\n",
    "data_type_counts = EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__).value_counts()\n",
    "\n",
    "# Printed the results\n",
    "for data_type, count in data_type_counts.items():\n",
    "    unique_values = EPA_df['ResultMeasureValue'][EPA_df['ResultMeasureValue'].apply(lambda x: type(x).__name__) == data_type].nunique()\n",
    "    print(f\"Data Type: {data_type}, Total Values: {count}, Unique Values: {unique_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069bfa03-2c0b-4130-9052-f55c99c7975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counted number of NaNs in results.\n",
    "nan_count = EPA_df['ResultMeasureValue'].isna().sum()\n",
    "print(nan_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e053be4-42eb-4a45-9ce0-4cacfc9659fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saved to CSV.\n",
    "EPA_df.to_csv('EPA_data10.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
